{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verify commands are correct:\n",
      "yt-dlp -f 'bv*[height<=360]+ba/b[height<=480]' -P /mnt/storage_hdd/thesis/yt_1b_dataset/yt_1b_train/parallel_0 --batch-file /home/kastan/thesis/video-pretrained-transformer/yt_download/__source/train_id_collection/yt_1b_train_id_list_0.txt --download-archive /mnt/storage_hdd/thesis/yt_1b_dataset/yt_1b_train/parallel_0/yt_1b_train_download_record_0.txt -P temp:/tmp -N 5 -o '%(id)s_%(channel)s_%(view_count)s_%(title)s.%(ext)s' --min-views 500 --proxy 69.30.217.114:19014 --write-subs\n",
      "Parallel downloads:  10\n"
     ]
    }
   ],
   "source": [
    "  import shlex\n",
    "  golden_command = \"\"\"yt-dlp -f 'bv*[height<=360]+ba/b[height<=480]' \\\n",
    "  -P /mnt/storage_hdd/thesis/yt_1b_dataset/yt_1b_train/parallel_{process_num} \\\n",
    "  --batch-file /home/kastan/thesis/video-pretrained-transformer/yt_download/__source/train_id_collection/yt_1b_train_id_list_{process_num}.txt \\\n",
    "  --download-archive /mnt/storage_hdd/thesis/yt_1b_dataset/yt_1b_train/parallel_{process_num}/yt_1b_train_download_record_{process_num}.txt \\\n",
    "  -P 'temp:/tmp' \\\n",
    "  -N 5 \\\n",
    "  -o '%(id)s_%(channel)s_%(view_count)s_%(title)s.%(ext)s' \\\n",
    "  --min-views 500 \\\n",
    "  --proxy 69.30.217.114:19014 \\\n",
    "  --write-subs\"\"\"\n",
    "  final_subprocess_commands = []\n",
    "  for i in range(10):\n",
    "    final_subprocess_commands.append(shlex.split(golden_command.format(process_num=i)))\n",
    "  print(\"Verify commands are correct:\")\n",
    "  print(shlex.join(final_subprocess_commands[0]))\n",
    "  # print()\n",
    "  # print(shlex.join(final_subprocess_commands[1]))\n",
    "  print(\"Parallel downloads: \", len(final_subprocess_commands))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get videos into handpicked folders\n",
    "\n",
    "[] `Wall Street Journal`\n",
    "[] `Corridor Crew`\n",
    "[] `CinemaSins`\n",
    "[] `Matt D'Avella`\n",
    "[] `Berm Peak`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "channel_list = ['wall_street_journal', 'corridor_crew', 'cinemasins', 'matt_davella', 'berm_peak']\n",
    "channel_human_list = ['Wall Street Journal', 'Corridor Crew', 'CinemaSins', 'Matt D\\'Avella', 'Berm Peak']\n",
    "\n",
    "root_dir = '/home/kastan/thesis/video-pretrained-transformer/yt_download'\n",
    "save_dir = '/mnt/storage_hdd/thesis/handpicked_downloads'\n",
    "\n",
    "file_list = os.listdir(root_dir)\n",
    "\n",
    "for channel_dir, channel_human_name in zip(channel_list, channel_human_list):\n",
    "  if not os.path.exists(os.path.join(save_dir, channel_dir)):\n",
    "    os.makedirs(os.path.join(save_dir, channel_dir), exist_ok=True)\n",
    "  \n",
    "  for name in file_list:\n",
    "    if channel_human_name in name:\n",
    "      # move file from root_dir to save_dir\n",
    "      if not os.path.exists(os.path.join(save_dir, channel_dir, name)):\n",
    "        shutil.copy(os.path.join(root_dir, name), os.path.join(save_dir, channel_dir))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import glob\n",
    "import time\n",
    "import os\n",
    "\n",
    "# dirs = \"/mnt/storage_hdd/thesis/yt_1b_dataset/yt_1b_train/parallel_0_json\"\n",
    "\n",
    "dirs = []\n",
    "for i in range(50,55):\n",
    "  dirs.append(f\"/mnt/storage_hdd/thesis/yt_1b_dataset/yt_1b_train/parallel_{i}\")\n",
    "\n",
    "total_input_files = 0\n",
    "all_file_stems = set()\n",
    "for json_dir in dirs:\n",
    "  if os.path.exists(json_dir):\n",
    "    files = glob.glob(os.path.join(json_dir, \"*\"))\n",
    "    # for file in files:\n",
    "    #   all_file_stems.add(pathlib.Path(file).stem)\n",
    "    #   total_input_files +=1\n",
    "    # all_files.update(set(files))\n",
    "    # print(f\"files: \", files[:5])\n",
    "    print(f'{json_dir} -- dir size {len(files)}')\n",
    "    print(f'Total input files {total_input_files}')\n",
    "    # print(f\"Num duplicates: {len(files) - len(set(files))}\")\n",
    "\n",
    "print(len(all_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q: how do I use range from 50 to 500 \n",
    "# A: use range(50, 500, 10) to get 50, 60, 70, ..., 490\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/storage_hdd/thesis/yt_1b_dataset/yt_1b_train/yt_1b_train_download_record_8.txt -- dir size 8\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/kastan/thesis/video-pretrained-transformer/downloading_formalized/dummy.ipynb Cell 7\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bkastan/home/kastan/thesis/video-pretrained-transformer/downloading_formalized/dummy.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m total_input_files \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bkastan/home/kastan/thesis/video-pretrained-transformer/downloading_formalized/dummy.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m all_files \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bkastan/home/kastan/thesis/video-pretrained-transformer/downloading_formalized/dummy.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mfor\u001b[39;00m root, dirs, files \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39mwalk(base_dir):\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bkastan/home/kastan/thesis/video-pretrained-transformer/downloading_formalized/dummy.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m   \u001b[39mfor\u001b[39;00m file \u001b[39min\u001b[39;00m files:\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bkastan/home/kastan/thesis/video-pretrained-transformer/downloading_formalized/dummy.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m     \u001b[39m# all_files.add(os.path.join(root, file))\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bkastan/home/kastan/thesis/video-pretrained-transformer/downloading_formalized/dummy.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39m# total_input_files +=1\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bkastan/home/kastan/thesis/video-pretrained-transformer/downloading_formalized/dummy.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mos\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(root, file)\u001b[39m}\u001b[39;00m\u001b[39m -- dir size \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(files)\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/utils/miniconda3/envs/nlp_v2/lib/python3.8/os.py:413\u001b[0m, in \u001b[0;36mwalk\u001b[0;34m(top, topdown, onerror, followlinks)\u001b[0m\n\u001b[1;32m    408\u001b[0m         \u001b[39m# Issue #23605: os.path.islink() is used instead of caching\u001b[39;00m\n\u001b[1;32m    409\u001b[0m         \u001b[39m# entry.is_symlink() result during the loop on os.scandir() because\u001b[39;00m\n\u001b[1;32m    410\u001b[0m         \u001b[39m# the caller can replace the directory entry during the \"yield\"\u001b[39;00m\n\u001b[1;32m    411\u001b[0m         \u001b[39m# above.\u001b[39;00m\n\u001b[1;32m    412\u001b[0m         \u001b[39mif\u001b[39;00m followlinks \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m islink(new_path):\n\u001b[0;32m--> 413\u001b[0m             \u001b[39myield from\u001b[39;00m walk(new_path, topdown, onerror, followlinks)\n\u001b[1;32m    414\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    415\u001b[0m     \u001b[39m# Recurse into sub-directories\u001b[39;00m\n\u001b[1;32m    416\u001b[0m     \u001b[39mfor\u001b[39;00m new_path \u001b[39min\u001b[39;00m walk_dirs:\n",
      "File \u001b[0;32m~/utils/miniconda3/envs/nlp_v2/lib/python3.8/os.py:362\u001b[0m, in \u001b[0;36mwalk\u001b[0;34m(top, topdown, onerror, followlinks)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    361\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 362\u001b[0m         entry \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(scandir_it)\n\u001b[1;32m    363\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[1;32m    364\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Count all files in dirs.\n",
    "\n",
    "import os\n",
    "# iterate through all files in a directory, using python dirwalk\n",
    "base_dir = \"/mnt/storage_hdd/thesis/yt_1b_dataset/yt_1b_train/\"\n",
    "total_input_files = 0\n",
    "all_files = set()\n",
    "\n",
    "for root, dirs, files in os.walk(base_dir):\n",
    "  for file in files:\n",
    "    # all_files.add(os.path.join(root, file))\n",
    "    # total_input_files +=1\n",
    "    print(f'{os.path.join(root, file)} -- dir size {len(files)}')\n",
    "    break\n",
    "    # print(f\"files: \", files[:5])\n",
    "    # print(f'{root} -- dir size {len(files)}')\n",
    "    # print(f'Total input files {total_input_files}')\n",
    "    # print(f\"Num duplicates: {len(files) - len(set(files))}\")\n",
    "\n",
    "print(len(all_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sleeping 10\n",
      "parallel_num:  53\n",
      "files:  9611\n",
      "New output dir:  ./test_new_location\n",
      "./test_new_location\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pathlib\n",
    "import glob\n",
    "import time\n",
    "\n",
    "VIDEO_FILE_OUTPUT_DIR = \"/mnt/storage_hdd/thesis/yt_1b_dataset/yt_1b_train/parallel_53\"\n",
    "\n",
    "def constrain_max_files_per_folder():\n",
    "  \"\"\" if we have more than 50k files in a folder, start a new one. \"\"\"\n",
    "  global VIDEO_FILE_OUTPUT_DIR\n",
    "  \n",
    "  print(\"sleeping 10\")\n",
    "  time.sleep(10) # every 10 min\n",
    "  while True:\n",
    "    out_dir = pathlib.Path(VIDEO_FILE_OUTPUT_DIR)\n",
    "    \n",
    "    parallel_num = VIDEO_FILE_OUTPUT_DIR.split(\"_\")[-1]\n",
    "    print(\"parallel_num: \", parallel_num)\n",
    "    \n",
    "    files = glob.glob(os.path.join(out_dir, \"*\"))\n",
    "    print(\"files: \", len(files))\n",
    "    \n",
    "    if True: #len(files) >= 50_000:\n",
    "      VIDEO_FILE_OUTPUT_DIR = './test_new_location' # os.path.join(out_dir.parent, f\"parallel_{int(parallel_num)+1}\")\n",
    "      print(\"New output dir: \", VIDEO_FILE_OUTPUT_DIR)\n",
    "      break\n",
    "\n",
    "    # time.sleep(60*10) # check every 10 min\n",
    "  \n",
    "constrain_max_files_per_folder()\n",
    "print(VIDEO_FILE_OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_v2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "612b182cb4c3e0acfd877acc6c10f43d075b0ae43380d6b249d2d2b5490153b2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
