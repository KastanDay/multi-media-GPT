{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply Transforms to Video datasets\n",
    "\n",
    "Good demo here (using Kinetics):\n",
    "https://pytorch.org/vision/stable/auto_examples/plot_video_api.html#sphx-glr-auto-examples-plot-video-api-py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kastan/utils/miniconda3/envs/nlp/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "torch.manual_seed(69)\n",
    "\n",
    "# !pip install -q pytube\n",
    "import cv2\n",
    "import numpy as np\n",
    "import skvideo.io\n",
    "import time\n",
    "import random\n",
    "from operator import itemgetter\n",
    "import sys\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    " \n",
    "sys.path.append('../../video-pretrained-transformer/')\n",
    "from whisper_audio.CaptionPreprocessing import CaptionPreprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO:(Pranav, Kastan) Define Dataset class\n",
    "\n",
    "This doesn't work yet, it's just examples from the docs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VPT_Dataset(Dataset):\n",
    "    \"\"\"TODO: Adapt this data class.\n",
    "    This doesn't work yet, it's just examples from the docs!\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        # TODO: Adapt this\n",
    "        Args: \n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        # self.landmarks_frame = pd.read_csv(csv_file)\n",
    "        # self.root_dir = root_dir\n",
    "        self.video_file = []\n",
    "        self.img_embeddings = []\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.landmarks_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        # todo: adapt this to our data\n",
    "        img_name = os.path.join(self.root_dir,\n",
    "                                self.landmarks_frame.iloc[idx, 0])\n",
    "        image = io.imread(img_name)\n",
    "        landmarks = self.landmarks_frame.iloc[idx, 1:]\n",
    "        landmarks = np.array([landmarks])\n",
    "        landmarks = landmarks.astype('float').reshape(-1, 2)\n",
    "        sample = {'image': image, 'landmarks': landmarks}\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Dataset transformations (using Compose)\n",
    "\n",
    "### Transformations used in X-CLIP\n",
    "\n",
    "We could probably steal their implementation, too: https://github.com/microsoft/VideoX/blob/master/X-CLIP/datasets/rand_augment.py\n",
    "\n",
    "```python\n",
    "_RAND_CHOICE_WEIGHTS_0 = {\n",
    "    \"Rotate\": 0.3,\n",
    "    \"ShearX\": 0.2,\n",
    "    \"ShearY\": 0.2,\n",
    "    \"TranslateXRel\": 0.1,\n",
    "    \"TranslateYRel\": 0.1,\n",
    "    \"Color\": 0.025,\n",
    "    \"Sharpness\": 0.025,\n",
    "    \"AutoContrast\": 0.025,\n",
    "    \"Solarize\": 0.005,\n",
    "    \"SolarizeAdd\": 0.005,\n",
    "    \"Contrast\": 0.005,\n",
    "    \"Brightness\": 0.005,\n",
    "    \"Equalize\": 0.005,\n",
    "    \"Posterize\": 0,\n",
    "    \"Invert\": 0,\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Torchscript (torch.jit.script) an optimizing JIT runtime compiler for PyTorch. \n",
    "# Compiled to C++, faster. I've read data augmentation is CPU-intensive, so this might help.\n",
    "\n",
    "# üìú ‚≠êÔ∏è Docs on all transforms: https://pytorch.org/vision/stable/transforms.html \n",
    "\n",
    "# Kastan's suggestions (helped by Copilot): \n",
    "# RandomRotation(degrees[, interpolation, ‚Ä¶])\n",
    "# RandomHorizontalFlip(p=0.5)\n",
    "# RandomVerticalFlip(p=0.5)\n",
    "# RandomResizedCrop(size, scale=(0.08, 1.0), ratio=(0.75, 1.3333333333333333), interpolation=2)\n",
    "# RandomCrop(size, padding=None, pad_if_needed=False, fill=0, padding_mode='constant')\n",
    "# RandomAffine(degrees, translate=None, scale=None, shear=None, resample=False, fillcolor=0)\n",
    "# RandomPerspective(distortion_scale=0.5, p=0.5, interpolation=3, fill=0)\n",
    "# RandomApply(transforms, p=0.5)\n",
    "# RandomChoice(transforms)\n",
    "# RandomOrder(transforms) \n",
    "# ColorJitter(brightness=0, contrast=0, saturation=0, hue=0)\n",
    "# Grayscale(num_output_channels=1)\n",
    "# Pad(padding, fill=0, padding_mode='constant')\n",
    "# LinearTransformation(transformation_matrix, mean_vector)\n",
    "# Normalize(mean, std, inplace=False)\n",
    "# Resize(size, interpolation=2)\n",
    "\n",
    "transforms = torch.nn.Sequential(\n",
    "    transforms.CenterCrop(10),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    ")\n",
    "scripted_transforms = torch.jit.script(transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "video_transforms = transforms.Compose([\n",
    "    transforms.PILToTensor(),\n",
    "    transforms.RandomHorizontalFlip(p=0.2),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ConvertImageDtype(torch.float),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO:(Pranav, Kastan) Instantiate Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataset = VPT_Dataset(\"./dataset\", epoch_size=None, transform=video_transforms)\n",
    "\n",
    "\n",
    "# TODO: This is just inspiration from the docs, pytorch datasets. THIS DOESN'T WORK yet\n",
    "loader = DataLoader(dataset, batch_size=12)\n",
    "data = {\"video\": [], 'start': [], 'end': [], 'tensorsize': []}\n",
    "for batch in loader:\n",
    "    for i in range(len(batch['path'])):\n",
    "        data['video'].append(batch['path'][i])\n",
    "        data['start'].append(batch['start'][i].item())\n",
    "        data['end'].append(batch['end'][i].item())\n",
    "        data['tensorsize'].append(batch['video'][i].size())\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/kastan/thesis/video-pretrained-transformer/data_preprocessing/Custom_PyTorch_Dataset.ipynb Cell 14\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B100.107.136.74/home/kastan/thesis/video-pretrained-transformer/data_preprocessing/Custom_PyTorch_Dataset.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m#Testing captionpreprocessing\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B100.107.136.74/home/kastan/thesis/video-pretrained-transformer/data_preprocessing/Custom_PyTorch_Dataset.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m process \u001b[39m=\u001b[39m CaptionPreprocessing()\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B100.107.136.74/home/kastan/thesis/video-pretrained-transformer/data_preprocessing/Custom_PyTorch_Dataset.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m process\u001b[39m.\u001b[39;49mload_mp4_to_wav(\u001b[39m\"\u001b[39;49m\u001b[39m/home/kastan/thesis/video-pretrained-transformer/data_preprocessing/test_4.mp4\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/thesis/video-pretrained-transformer/data_preprocessing/../../video-pretrained-transformer/whisper_audio/CaptionPreprocessing.py:37\u001b[0m, in \u001b[0;36mCaptionPreprocessing.load_mp4_to_wav\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m     33\u001b[0m dst \u001b[39m=\u001b[39m base_name \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m.wav\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     36\u001b[0m \u001b[39m# convert mp4 to wav\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m sound \u001b[39m=\u001b[39m AudioSegment\u001b[39m.\u001b[39;49mfrom_file(path,\u001b[39mformat\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mmp4\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     38\u001b[0m sound\u001b[39m.\u001b[39mexport(dst, \u001b[39mformat\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mwav\u001b[39m\u001b[39m\"\u001b[39m, parameters\u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39m-ac\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m1\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m     39\u001b[0m \u001b[39mreturn\u001b[39;00m dst\n",
      "File \u001b[0;32m~/utils/miniconda3/envs/nlp/lib/python3.8/site-packages/pydub/audio_segment.py:734\u001b[0m, in \u001b[0;36mAudioSegment.from_file\u001b[0;34m(cls, file, format, codec, parameters, start_second, duration, **kwargs)\u001b[0m\n\u001b[1;32m    730\u001b[0m audio_streams \u001b[39m=\u001b[39m [x \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m info[\u001b[39m'\u001b[39m\u001b[39mstreams\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m    731\u001b[0m                  \u001b[39mif\u001b[39;00m x[\u001b[39m'\u001b[39m\u001b[39mcodec_type\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39maudio\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m    732\u001b[0m \u001b[39m# This is a workaround for some ffprobe versions that always say\u001b[39;00m\n\u001b[1;32m    733\u001b[0m \u001b[39m# that mp3/mp4/aac/webm/ogg files contain fltp samples\u001b[39;00m\n\u001b[0;32m--> 734\u001b[0m audio_codec \u001b[39m=\u001b[39m audio_streams[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mcodec_name\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    735\u001b[0m \u001b[39mif\u001b[39;00m (audio_streams[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39msample_fmt\u001b[39m\u001b[39m'\u001b[39m) \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mfltp\u001b[39m\u001b[39m'\u001b[39m \u001b[39mand\u001b[39;00m\n\u001b[1;32m    736\u001b[0m         audio_codec \u001b[39min\u001b[39;00m [\u001b[39m'\u001b[39m\u001b[39mmp3\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mmp4\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39maac\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mwebm\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mogg\u001b[39m\u001b[39m'\u001b[39m]):\n\u001b[1;32m    737\u001b[0m     bits_per_sample \u001b[39m=\u001b[39m \u001b[39m16\u001b[39m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "#Testing captionpreprocessing\n",
    "process = CaptionPreprocessing()\n",
    "process.load_mp4_to_wav(\"/home/kastan/thesis/video-pretrained-transformer/data_preprocessing/test_4.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/kastan/thesis/video-pretrained-transformer/data_preprocessing/test_4.wav\"\n",
    "dir = '/'.join(path.split(\"/\")[:-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process.get_segments_thresholded()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import subprocess\n",
    "import os\n",
    "# Imports \n",
    "from lhotse import CutSet, RecordingSet, align_with_torchaudio, annotate_with_whisper\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint\n",
    "from dataclasses import asdict\n",
    "import torch\n",
    "from os import path\n",
    "from pydub import AudioSegment\n",
    "sys.path.append('../../video-pretrained-transformer/')\n",
    "from whisper_audio.CaptionPreprocessing import CaptionPreprocessing\n",
    "\n",
    "# Pranav's CLIP Video Pre-Processing\n",
    "\n",
    "# We want to extract EXACTLY n frames from a video given a start and end time\n",
    "# We also want to use random sampling if possible (1-30 fps for now)\n",
    "# def get_frames(video_path, n_frames = 60, words = 15, threshold_words = 30)\n",
    "#   frame_rate = get_frame_rate(video_path)\n",
    "#   list_of_start_end_dict = CaptionPreprocessing(video_path)\n",
    "#   for start_end_dict in list_of_start_end_dict:\n",
    "#       start, end = start_end_dict['start'], start_end_dict['end']\n",
    "#       if end - start < n_frames/frame_rate:\n",
    "#           return ERROR\n",
    "#       Get random frames\n",
    "\n",
    "class YoutubeDataPreprocessor:\n",
    "    def __init__(self, data_path, extension=\".mp4\", debug=False):\n",
    "        self.data_path = data_path\n",
    "        self.extension = extension\n",
    "        self.debug = debug\n",
    "        self.caption_preprocessor = CaptionPreprocessing()\n",
    "\n",
    "    def write_resampled_video(self, video_reader, resample_name, frames_per_partition=64, num_partitions=5, frame_separation=3, extension=\".mp4\"):\n",
    "        num_frames, height, width, channels = video_reader.getShape()\n",
    "\n",
    "        num_frames_processed_per_partition = (frames_per_partition-1)*frame_separation+frames_per_partition\n",
    "        partitions = []\n",
    "        \n",
    "        all_frames = set([i for i in range(num_frames-num_frames_processed_per_partition-1)])\n",
    "\n",
    "        for partition in range(num_partitions):\n",
    "            retry = 0\n",
    "            no_partition_flag = False\n",
    "            while True:\n",
    "                if retry == 5:\n",
    "                    no_partition_flag = True\n",
    "                    break\n",
    "\n",
    "                # random_start_idx = random.chouce(0, num_frames-num_frames_processed_per_partition-1)\n",
    "\n",
    "                # TODO: ADD IN CHECK FOR NUMBER OF WORDS IN SEGMENT\n",
    "                random_start_idx = random.choice(list(all_frames))\n",
    "                if True:\n",
    "                    partition = set([i for i in range(random_start_idx, random_start_idx+num_frames_processed_per_partition)])\n",
    "                    all_frames = all_frames - partition\n",
    "                    break\n",
    "\n",
    "                retry += 1\n",
    "            \n",
    "            if no_partition_flag:\n",
    "                break\n",
    "\n",
    "            frames_in_partition = []\n",
    "            curr_frame = random_start_idx\n",
    "\n",
    "            frames_in_partition = list(range(random_start_idx, random_start_idx+num_frames_processed_per_partition, frame_separation+1))\n",
    "\n",
    "            assert len(frames_in_partition) == frames_per_partition\n",
    "            \n",
    "            partitions.append(frames_in_partition)\n",
    "        \n",
    "        if len(partitions) < num_partitions:\n",
    "            print(f\"[WARNING] {resample_name} has less than {num_partitions} (number of partitions: {len(partitions)})\")\n",
    "\n",
    "        partitions = sorted(partitions, key=itemgetter(0))\n",
    "\n",
    "        writer = None\n",
    "        curr_partition_end = 0\n",
    "        curr_frame = 0\n",
    "        frames_to_extract = []\n",
    "        partition_num = 0\n",
    "\n",
    "        curr_partition = 0\n",
    "        writer = skvideo.io.FFmpegWriter(f\"{resample_name}_{curr_partition}{extension}\")\n",
    "\n",
    "        for frame in video_reader.nextFrame():\n",
    "            if curr_frame >= partitions[curr_partition][-1]:\n",
    "                if writer is not None:\n",
    "                    # print(\"closedd....\")\n",
    "                    writer.close()\n",
    "                    writer = None\n",
    "\n",
    "                curr_partition += 1\n",
    "                writer = skvideo.io.FFmpegWriter(f\"{resample_name}_{curr_partition}{extension}\")\n",
    "\n",
    "                if self.debug:\n",
    "                    print(f\"{resample_name}_{curr_partition}{extension}\")\n",
    "\n",
    "            if curr_partition >= len(partitions):\n",
    "                # print(\"broken\")\n",
    "                break\n",
    "            \n",
    "            if curr_frame in partitions[curr_partition]:\n",
    "                # print(\"hit\")\n",
    "                writer.writeFrame(frame)\n",
    "                \n",
    "            curr_frame += 1\n",
    "\n",
    "\n",
    "        # if writer is not None:\n",
    "        #     writer.close()\n",
    "        \n",
    "        return\n",
    "\n",
    "    def process_video_old(self, video_name):\n",
    "        video_reader = skvideo.io.FFmpegReader(video_name)\n",
    "        start = time.time()\n",
    "        self.write_resampled_video(video_reader, f\"./test\", frames_per_partition=64, num_partitions=5, frame_separation=3, extension=\".mp4\")\n",
    "        end = time.time() - start\n",
    "\n",
    "        if self.debug:\n",
    "            print(f\"[INFO] video took {end} s for resampling\")\n",
    "\n",
    "        video_reader.close()\n",
    "\n",
    "    # def get_frames(video_path, n_frames = 60, words = 15, threshold_words = 30)\n",
    "    #   frame_rate = get_frame_rate(video_path)\n",
    "    #   list_of_start_end_dict = CaptionPreprocessing(video_path)\n",
    "    #   for start_end_dict in list_of_start_end_dict:\n",
    "    #       start, end = start_end_dict['start'], start_end_dict['end']\n",
    "    #       if end - start < n_frames/frame_rate:\n",
    "    #           return ERROR\n",
    "    #       Get random frames\n",
    "\n",
    "    def process_video(self, video_name):\n",
    "        # self.caption_preprocessor.process_mp4(video_name)\n",
    "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        dir = '/'.join(video_name.split(\"/\")[:-1])\n",
    "        recordings = RecordingSet.from_dir(dir, pattern=\"*.wav\")\n",
    "        cuts = annotate_with_whisper(recordings, device = device)\n",
    "        cuts_aligned = align_with_torchaudio(cuts, device = device)\n",
    "        for cut in cuts_aligned:\n",
    "            cut = asdict(cut)\n",
    "        \n",
    "        # return cuts_aligned\n",
    "        segment_timestamps = self.caption_preprocessor.get_segments_thresholded(cut)\n",
    "        # print(segment_timestamps)\n",
    "        return segment_timestamps\n",
    "    \n",
    "\n",
    "    def process_video_dataset(self):\n",
    "        for f in os.listdir(self.data_path):\n",
    "            if f.endswith(self.extension):\n",
    "                self.process_video(os.path.join(self.data_path, f))\n",
    "            else:\n",
    "                continue\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning audio files (*.wav): 1it [00:00, 4084.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'start': 3.9909375, 'end': 25.9335625, 'segment_word_list': [{'word': 'VIDEO', 'start': 3.9909375, 'end': 6.6381875}, {'word': 'RECORD', 'start': 6.7785625, 'end': 7.119437499999999}, {'word': 'ENABLE', 'start': 9.972375, 'end': 10.179812499999999}, {'word': 'DELINSTANT', 'start': 13.3415625, 'end': 15.471125}, {'word': \"THEY'RE\", 'start': 18.821, 'end': 19.124375}, {'word': 'ALL', 'start': 19.1836875, 'end': 19.2855625}, {'word': 'STRANGERS', 'start': 19.344875, 'end': 19.7086875}, {'word': 'TO', 'start': 20.21125, 'end': 20.33325}, {'word': 'LOVE', 'start': 20.3724375, 'end': 20.93775}, {'word': 'THEY', 'start': 22.821625, 'end': 22.9444375}, {'word': 'KNOW', 'start': 23.105, 'end': 23.34925}, {'word': 'THE', 'start': 23.388375, 'end': 23.632625}, {'word': 'RULES', 'start': 23.692, 'end': 24.0981875}, {'word': 'AND', 'start': 24.46075, 'end': 24.542875000000002}, {'word': 'SO', 'start': 24.642125, 'end': 24.9258125}]}, {'start': 25.2065, 'end': 36.772375, 'segment_word_list': [{'word': 'DO', 'start': 25.2065, 'end': 25.490187499999998}, {'word': 'I', 'start': 25.9119375, 'end': 25.9335625}, {'word': \"I'VE\", 'start': 27.10125, 'end': 27.2845}, {'word': 'GOT', 'start': 27.3231875, 'end': 27.546812499999998}, {'word': 'COMMITMENTS', 'start': 27.565375, 'end': 28.354062499999998}, {'word': 'FOR', 'start': 28.3725625, 'end': 28.616375}, {'word': 'LIFE', 'start': 28.655125, 'end': 28.8585625}, {'word': 'YOU', 'start': 29.5011875, 'end': 29.663625}, {'word': \"WON'T\", 'start': 29.7220625, 'end': 32.093312499999996}, {'word': 'GET', 'start': 32.111625, 'end': 32.2740625}, {'word': 'THIS', 'start': 32.3325, 'end': 32.535125}, {'word': 'WRONG', 'start': 32.6336875, 'end': 33.519}, {'word': 'ANY', 'start': 33.5775, 'end': 33.6796875}, {'word': 'OTHER', 'start': 33.8184375, 'end': 34.0611875}, {'word': 'GUY', 'start': 34.0795, 'end': 34.141562500000006}]}, {'start': 36.428875, 'end': 43.9803125, 'segment_word_list': [{'word': 'I', 'start': 36.428875, 'end': 36.531375}, {'word': 'JUST', 'start': 36.5694375, 'end': 36.772375}, {'word': 'WANNA', 'start': 36.89075, 'end': 37.294437499999994}, {'word': 'TELL', 'start': 37.3325, 'end': 37.6358125}, {'word': 'YOU', 'start': 37.6538125, 'end': 37.7965}, {'word': 'HOW', 'start': 37.995125, 'end': 38.1779375}, {'word': 'I', 'start': 38.236125, 'end': 38.3586875}, {'word': 'FEEL', 'start': 38.4168125, 'end': 39.00125}, {'word': 'I', 'start': 39.300625, 'end': 39.605062499999995}, {'word': 'GOTTA', 'start': 40.5086875, 'end': 40.813125}, {'word': 'MAKE', 'start': 40.851, 'end': 40.994375}, {'word': 'YOU', 'start': 41.3140625, 'end': 41.4373125}, {'word': 'UNDERSTAND', 'start': 41.515375, 'end': 42.1218125}, {'word': 'NEVER', 'start': 42.3615625, 'end': 42.7884375}, {'word': 'GONNA', 'start': 43.3716875, 'end': 43.657125}]}, {'start': 43.6949375, 'end': 50.887625, 'segment_word_list': [{'word': 'GIVE', 'start': 43.6949375, 'end': 43.8995625}, {'word': 'YOU', 'start': 43.917125, 'end': 43.9803125}, {'word': 'UP', 'start': 44.1595625, 'end': 44.2025625}, {'word': 'NEVER', 'start': 44.341375, 'end': 44.465312499999996}, {'word': 'GONNA', 'start': 44.543375, 'end': 45.515812499999996}, {'word': 'LET', 'start': 45.5736875, 'end': 45.65725}, {'word': 'YOU', 'start': 45.6746875, 'end': 45.75825}, {'word': 'DOWN', 'start': 45.816125, 'end': 45.9805}, {'word': 'NEVER', 'start': 46.2, 'end': 46.545125000000006}, {'word': 'GONNA', 'start': 46.562375, 'end': 47.350437500000005}, {'word': 'RUN', 'start': 47.4684375, 'end': 47.632375}, {'word': 'AROUND', 'start': 47.7301875, 'end': 48.457875}, {'word': 'IT', 'start': 48.5758125, 'end': 48.659187499999994}, {'word': \"HE'S\", 'start': 49.7918125, 'end': 49.8765}, {'word': 'HURT', 'start': 49.91425, 'end': 50.039750000000005}]}, {'start': 50.0775, 'end': 58.9753125, 'segment_word_list': [{'word': 'YOU', 'start': 50.0775, 'end': 50.14175}, {'word': 'NEVER', 'start': 50.3811875, 'end': 50.887625}, {'word': 'GONNA', 'start': 50.9248125, 'end': 52.095687500000004}, {'word': 'MAKE', 'start': 52.153, 'end': 52.458124999999995}, {'word': 'YOU', 'start': 52.5355625, 'end': 52.880937499999995}, {'word': 'CRY', 'start': 52.93825, 'end': 53.08231249999999}, {'word': 'NEVER', 'start': 53.7858125, 'end': 53.95075}, {'word': 'GONNA', 'start': 53.987875, 'end': 54.213375}, {'word': 'SAY', 'start': 54.2706875, 'end': 54.7790625}, {'word': 'GOODBYE', 'start': 54.8363125, 'end': 55.1628125}, {'word': 'NEVER', 'start': 55.72525, 'end': 56.6579375}, {'word': 'GONNA', 'start': 56.6949375, 'end': 56.880187500000005}, {'word': 'TELL', 'start': 56.917125, 'end': 57.04175}, {'word': 'THE', 'start': 57.0585625, 'end': 57.1225625}, {'word': 'LIE', 'start': 57.139375, 'end': 57.203375}]}, {'start': 57.7234375, 'end': 67.6081875, 'segment_word_list': [{'word': 'AND', 'start': 57.7234375, 'end': 58.4316875}, {'word': 'HURT', 'start': 58.5086875, 'end': 58.9753125}, {'word': 'YOU', 'start': 59.0120625, 'end': 59.1565625}, {'word': \"WE'VE\", 'start': 60.8431875, 'end': 61.1283125}, {'word': 'KNOWN', 'start': 61.1446875, 'end': 61.389625}, {'word': 'EACH', 'start': 61.4461875, 'end': 61.61075}, {'word': 'OTHER', 'start': 61.808, 'end': 62.1333125}, {'word': 'FOR', 'start': 62.1496875, 'end': 63.1785625}, {'word': 'SO', 'start': 63.2150625, 'end': 63.5203125}, {'word': 'LONG', 'start': 63.637125, 'end': 64.12325}, {'word': 'YOUR', 'start': 65.06575, 'end': 65.57306249999999}, {'word': \"HEART'S\", 'start': 65.6295, 'end': 65.8750625}, {'word': 'BEEN', 'start': 65.89125, 'end': 66.0965625}, {'word': 'ACHING', 'start': 66.11275, 'end': 66.3785}, {'word': 'BUT', 'start': 66.434875, 'end': 66.700625}]}, {'start': 67.2, 'end': 74.03275000000001, 'segment_word_list': [{'word': \"YOU'RE\", 'start': 67.2, 'end': 67.4061875}, {'word': 'TOO', 'start': 67.442375, 'end': 67.6081875}, {'word': 'SHY', 'start': 67.6848125, 'end': 68.1940625}, {'word': 'TO', 'start': 68.2706875, 'end': 68.41624999999999}, {'word': 'SAY', 'start': 68.513125, 'end': 68.8809375}, {'word': 'IT', 'start': 68.917125, 'end': 69.0223125}, {'word': 'YOU', 'start': 69.56175, 'end': 69.787125}, {'word': 'SAID', 'start': 69.8230625, 'end': 70.02837500000001}, {'word': \"WE'VE\", 'start': 70.084375, 'end': 70.2896875}, {'word': 'ALL', 'start': 70.4663125, 'end': 70.6515}, {'word': 'KNOWN', 'start': 70.8683125, 'end': 71.11381250000001}, {'word': \"WHAT'S\", 'start': 71.411, 'end': 71.736875}, {'word': 'BEEN', 'start': 71.7728125, 'end': 72.2394375}, {'word': 'GOING', 'start': 72.3155625, 'end': 72.4806875}, {'word': 'ON', 'start': 72.576875, 'end': 72.64150000000001}]}, {'start': 73.5231875, 'end': 81.52206249999999, 'segment_word_list': [{'word': 'WE', 'start': 73.5231875, 'end': 73.77012500000001}, {'word': 'KNOW', 'start': 73.8868125, 'end': 74.03275000000001}, {'word': 'THE', 'start': 74.068625, 'end': 74.2348125}, {'word': 'GAME', 'start': 74.2505, 'end': 74.436875}, {'word': \"I'M\", 'start': 74.4525, 'end': 74.6590625}, {'word': 'WITH', 'start': 74.6949375, 'end': 74.98231249999999}, {'word': 'GONNA', 'start': 75.6848125, 'end': 75.931875}, {'word': 'PLAY', 'start': 75.967625, 'end': 76.1339375}, {'word': 'IT', 'start': 76.2505, 'end': 76.7198125}, {'word': 'AND', 'start': 77.702, 'end': 78.8111875}, {'word': 'IF', 'start': 78.8866875, 'end': 78.95174999999999}, {'word': 'YOU', 'start': 79.0875, 'end': 79.31318750000001}, {'word': 'ASK', 'start': 79.5895, 'end': 79.81518750000001}, {'word': 'ME', 'start': 79.870625, 'end': 80.09631250000001}, {'word': 'HOW', 'start': 80.27225, 'end': 80.3975}]}, {'start': 80.4730625, 'end': 88.01343750000001, 'segment_word_list': [{'word': 'I', 'start': 80.4730625, 'end': 80.6184375}, {'word': 'FEEL', 'start': 80.673875, 'end': 81.52206249999999}, {'word': 'IT', 'start': 81.557375, 'end': 81.62243749999999}, {'word': \"DON'T\", 'start': 82.502, 'end': 82.7084375}, {'word': 'TELL', 'start': 82.7234375, 'end': 83.01043750000001}, {'word': 'ME', 'start': 83.0255, 'end': 83.27218749999999}, {'word': \"YOU'RE\", 'start': 83.3275, 'end': 83.53393750000001}, {'word': 'TOO', 'start': 83.569125, 'end': 83.7956875}, {'word': 'GLAD', 'start': 84.0925625, 'end': 84.33924999999999}, {'word': 'TO', 'start': 84.3744375, 'end': 84.580875}, {'word': 'SEE', 'start': 84.5959375, 'end': 84.76212500000001}, {'word': 'NEVER', 'start': 85.4828125, 'end': 86.19518749999999}, {'word': 'GONNA', 'start': 86.3515, 'end': 86.5588125}, {'word': 'GIVE', 'start': 86.5939375, 'end': 86.72043749999999}, {'word': 'YOU', 'start': 86.7555, 'end': 86.841625}]}, {'start': 86.917125, 'end': 94.78156249999999, 'segment_word_list': [{'word': 'UP', 'start': 86.917125, 'end': 86.9628125}, {'word': 'NEVER', 'start': 87.6241875, 'end': 88.01343750000001}, {'word': 'GONNA', 'start': 88.068625, 'end': 88.39725}, {'word': 'LET', 'start': 88.4525, 'end': 88.6195625}, {'word': 'YOU', 'start': 88.6545, 'end': 88.8215625}, {'word': 'DOWN', 'start': 88.8565625, 'end': 88.9831875}, {'word': 'NEVER', 'start': 89.3811875, 'end': 89.6081875}, {'word': 'GONNA', 'start': 89.6630625, 'end': 90.19212499999999}, {'word': 'RUN', 'start': 90.4885625, 'end': 90.7155625}, {'word': 'AROUND', 'start': 90.8106875, 'end': 91.661875}, {'word': 'IT', 'start': 91.6765, 'end': 91.7625625}, {'word': \"HE'S\", 'start': 92.5469375, 'end': 92.7771875}, {'word': 'HURT', 'start': 92.832625, 'end': 92.98118749999999}, {'word': 'YOU', 'start': 93.0775, 'end': 93.164875}, {'word': 'NEVER', 'start': 93.9070625, 'end': 94.3775}]}, {'start': 94.4120625, 'end': 101.4885625, 'segment_word_list': [{'word': 'GONNA', 'start': 94.4120625, 'end': 94.6400625}, {'word': 'MAKE', 'start': 94.6949375, 'end': 94.78156249999999}, {'word': 'YOU', 'start': 94.816125, 'end': 94.9229375}, {'word': 'CRY', 'start': 94.9373125, 'end': 95.0036875}, {'word': 'NEVER', 'start': 95.987875, 'end': 96.21600000000001}, {'word': 'GONNA', 'start': 96.2505, 'end': 96.4584375}, {'word': 'SAY', 'start': 96.492875, 'end': 96.7614375}, {'word': 'GOODBYE', 'start': 96.7959375, 'end': 97.1856875}, {'word': 'NEVER', 'start': 97.987875, 'end': 98.3575625}, {'word': 'GONNA', 'start': 98.391875, 'end': 98.5999375}, {'word': 'TELL', 'start': 98.6343125, 'end': 98.80199999999999}, {'word': 'THE', 'start': 98.816125, 'end': 98.9231875}, {'word': 'LIE', 'start': 98.97775, 'end': 99.044375}, {'word': 'AND', 'start': 99.240375, 'end': 99.36775}, {'word': 'HURT', 'start': 100.492875, 'end': 100.680875}]}, {'start': 100.7555, 'end': 109.1764375, 'segment_word_list': [{'word': 'YOU', 'start': 100.7555, 'end': 101.0040625}, {'word': 'NEVER', 'start': 101.280625, 'end': 101.4885625}, {'word': 'GONNA', 'start': 101.502375, 'end': 102.819125}, {'word': 'GIVE', 'start': 102.8531875, 'end': 103.12156250000001}, {'word': 'YOU', 'start': 103.2765625, 'end': 103.3836875}, {'word': 'UP', 'start': 103.4176875, 'end': 103.4643125}, {'word': 'NEVER', 'start': 104.42575, 'end': 104.654}, {'word': 'GONNA', 'start': 104.687875, 'end': 104.91612500000001}, {'word': 'LET', 'start': 104.95, 'end': 105.198375}, {'word': 'YOU', 'start': 105.3330625, 'end': 105.5209375}, {'word': 'DOWN', 'start': 105.534625, 'end': 105.68218750000001}, {'word': 'NEVER', 'start': 106.28075, 'end': 106.5095625}, {'word': 'GONNA', 'start': 106.543375, 'end': 106.7721875}, {'word': 'RUN', 'start': 106.9474375, 'end': 107.07525000000001}, {'word': 'AROUND', 'start': 107.3515, 'end': 107.8429375}]}, {'start': 107.8969375, 'end': 116.303375, 'segment_word_list': [{'word': 'IT', 'start': 107.8969375, 'end': 107.9439375}, {'word': \"HE'S\", 'start': 108.402, 'end': 109.1764375}, {'word': 'HURT', 'start': 109.189875, 'end': 109.56025}, {'word': 'YOU', 'start': 109.5736875, 'end': 109.66125000000001}, {'word': 'NEVER', 'start': 111.3110625, 'end': 111.540125}, {'word': 'GONNA', 'start': 111.6949375, 'end': 111.8431875}, {'word': 'MAKE', 'start': 111.8565625, 'end': 111.94425}, {'word': 'YOU', 'start': 111.9575625, 'end': 112.02499999999999}, {'word': 'CRY', 'start': 112.038375, 'end': 112.206875}, {'word': 'NEVER', 'start': 112.8826875, 'end': 113.1105625}, {'word': 'GONNA', 'start': 113.1236875, 'end': 113.311375}, {'word': 'SING', 'start': 113.3445625, 'end': 113.91381249999999}, {'word': 'GOOD', 'start': 113.9469375, 'end': 114.134625}, {'word': 'NIGHT', 'start': 114.1879375, 'end': 114.937875}, {'word': 'NEVER', 'start': 115.0915625, 'end': 115.48006249999999}]}, {'start': 115.5333125, 'end': 128.69037500000002, 'segment_word_list': [{'word': 'GONNA', 'start': 115.5333125, 'end': 116.0423125}, {'word': 'TELL', 'start': 116.0755, 'end': 116.303375}, {'word': 'THE', 'start': 116.3164375, 'end': 116.56437500000001}, {'word': 'LIE', 'start': 116.8385, 'end': 117.0463125}, {'word': 'AND', 'start': 117.442375, 'end': 117.570875}, {'word': 'HURT', 'start': 117.664625, 'end': 118.0961875}, {'word': 'YOU', 'start': 118.1696875, 'end': 118.2981875}, {'word': 'IF', 'start': 119.783875, 'end': 120.11343749999999}, {'word': 'YOU', 'start': 120.911375, 'end': 121.82481250000001}, {'word': 'ARE', 'start': 121.93825, 'end': 122.0463125}, {'word': 'IF', 'start': 122.280375, 'end': 122.5895}, {'word': 'YOU', 'start': 122.682375, 'end': 122.7905}, {'word': 'ARE', 'start': 123.8683125, 'end': 124.03675}, {'word': 'IF', 'start': 126.543375, 'end': 126.69262499999999}, {'word': 'YOU', 'start': 126.705, 'end': 126.8340625}]}, {'start': 126.987875, 'end': 137.3903125, 'segment_word_list': [{'word': 'ARE', 'start': 126.987875, 'end': 127.137125}, {'word': 'NEVER', 'start': 128.4411875, 'end': 128.69037500000002}, {'word': 'GONNA', 'start': 128.7225625, 'end': 128.951625}, {'word': 'GIVE', 'start': 128.9638125, 'end': 129.233125}, {'word': 'NEVER', 'start': 129.325625, 'end': 129.4944375}, {'word': 'GONNA', 'start': 129.5065, 'end': 129.7355625}, {'word': 'GIVE', 'start': 129.7879375, 'end': 130.037125}, {'word': 'NEVER', 'start': 132.3409375, 'end': 132.792125}, {'word': 'GONNA', 'start': 132.804, 'end': 133.174625}, {'word': 'GIVE', 'start': 133.2066875, 'end': 133.5975}, {'word': 'NEVER', 'start': 133.649625, 'end': 133.95987499999998}, {'word': 'GONNA', 'start': 134.0120625, 'end': 134.523625}, {'word': 'GIVE', 'start': 134.5556875, 'end': 134.8659375}, {'word': 'IF', 'start': 136.2706875, 'end': 136.68312500000002}, {'word': 'YOU', 'start': 136.8969375, 'end': 137.04675}]}, {'start': 137.0585625, 'end': 144.5018125, 'segment_word_list': [{'word': 'ARE', 'start': 137.0585625, 'end': 137.12756249999998}, {'word': \"WE'VE\", 'start': 137.2605625, 'end': 137.3903125}, {'word': 'KNOWN', 'start': 137.402, 'end': 137.55193749999998}, {'word': 'EACH', 'start': 137.563625, 'end': 137.6731875}, {'word': 'OTHER', 'start': 137.806, 'end': 138.097375}, {'word': 'SO', 'start': 139.3005, 'end': 139.47}, {'word': 'LONG', 'start': 139.5215625, 'end': 140.63575}, {'word': 'YOUR', 'start': 141.0894375, 'end': 141.3393125}, {'word': \"HEART'S\", 'start': 141.411, 'end': 141.6206875}, {'word': 'BEEN', 'start': 141.65225, 'end': 141.96243750000002}, {'word': 'ACHING', 'start': 142.0140625, 'end': 142.40462499999998}, {'word': 'BUT', 'start': 142.45625, 'end': 142.82675}, {'word': \"YOU'RE\", 'start': 143.2201875, 'end': 143.4513125}, {'word': 'JUST', 'start': 143.4828125, 'end': 143.6735625}, {'word': 'SHY', 'start': 143.7454375, 'end': 144.03718750000002}]}, {'start': 144.12925, 'end': 151.2595, 'segment_word_list': [{'word': 'AS', 'start': 144.12925, 'end': 144.2391875}, {'word': 'TO', 'start': 144.290875, 'end': 144.5018125}, {'word': 'SAY', 'start': 144.5736875, 'end': 144.82500000000002}, {'word': \"IT'S\", 'start': 145.4411875, 'end': 145.59093750000002}, {'word': 'HAPPY', 'start': 145.6421875, 'end': 145.83212500000002}, {'word': 'FOR', 'start': 145.883375, 'end': 146.033125}, {'word': 'THE', 'start': 146.1045, 'end': 146.374875}, {'word': \"WHAT'S\", 'start': 146.406, 'end': 146.636125}, {'word': 'BEEN', 'start': 146.9085, 'end': 147.1989375}, {'word': 'GOING', 'start': 147.431125, 'end': 148.04318750000002}, {'word': 'ON', 'start': 148.1949375, 'end': 148.56581250000002}, {'word': 'WE', 'start': 149.56175, 'end': 149.83237499999998}, {'word': 'KNOW', 'start': 149.8431875, 'end': 150.0735625}, {'word': 'THE', 'start': 150.1045, 'end': 150.27462500000001}, {'word': 'GAME', 'start': 150.325625, 'end': 150.6163125}]}, {'start': 150.727625, 'end': 160.2449375, 'segment_word_list': [{'word': 'AND', 'start': 150.727625, 'end': 150.8575}, {'word': \"WE'RE\", 'start': 150.9085, 'end': 151.2595}, {'word': 'GONNA', 'start': 151.7125625, 'end': 152.72687499999998}, {'word': 'PLAY', 'start': 152.75775, 'end': 152.90775}, {'word': 'IT', 'start': 152.9185625, 'end': 152.9680625}, {'word': 'I', 'start': 154.6673125, 'end': 154.777375}, {'word': 'JUST', 'start': 154.828125, 'end': 155.0386875}, {'word': 'WANNA', 'start': 155.1496875, 'end': 155.5813125}, {'word': 'TELL', 'start': 155.612, 'end': 155.842625}, {'word': 'YOU', 'start': 155.8934375, 'end': 156.0436875}, {'word': 'HOW', 'start': 156.275375, 'end': 156.3854375}, {'word': 'I', 'start': 156.476375, 'end': 156.64675}, {'word': 'FEEL', 'start': 156.6974375, 'end': 156.98837500000002}, {'word': 'I', 'start': 157.46125, 'end': 157.73237500000002}, {'word': 'GOTTA', 'start': 158.7678125, 'end': 159.079125}]}, {'start': 159.1095, 'end': 167.0890625, 'segment_word_list': [{'word': 'MAKE', 'start': 159.1095, 'end': 159.23987499999998}, {'word': 'YOU', 'start': 159.25025, 'end': 160.2449375}, {'word': 'UNDERSTAND', 'start': 160.25525, 'end': 161.0690625}, {'word': 'NEVER', 'start': 162.3716875, 'end': 162.58375}, {'word': 'GONNA', 'start': 162.5939375, 'end': 162.765625}, {'word': 'GIVE', 'start': 162.7959375, 'end': 163.04837500000002}, {'word': 'YOU', 'start': 163.0585625, 'end': 163.1494375}, {'word': 'UP', 'start': 163.1595625, 'end': 163.20999999999998}, {'word': 'NEVER', 'start': 163.866625, 'end': 164.058625}, {'word': 'GONNA', 'start': 164.088875, 'end': 164.4425}, {'word': 'LET', 'start': 164.4525, 'end': 164.68487499999998}, {'word': 'YOU', 'start': 164.715125, 'end': 164.8666875}, {'word': 'DOWN', 'start': 164.8969375, 'end': 165.008125}, {'word': 'NEVER', 'start': 165.301, 'end': 165.493125}, {'word': 'GONNA', 'start': 165.7858125, 'end': 166.56381249999998}]}, {'start': 166.6746875, 'end': 174.0794375, 'segment_word_list': [{'word': 'RUN', 'start': 166.6746875, 'end': 166.7658125}, {'word': 'AROUND', 'start': 166.917125, 'end': 167.0890625}, {'word': 'IT', 'start': 167.0989375, 'end': 167.21025}, {'word': 'YOU', 'start': 167.28075, 'end': 167.4931875}, {'word': 'SAID', 'start': 167.5231875, 'end': 167.776}, {'word': 'YOU', 'start': 168.3313125, 'end': 168.5235625}, {'word': \"YOU'RE\", 'start': 169.92725, 'end': 170.4024375}, {'word': 'GONNA', 'start': 170.4323125, 'end': 170.58425}, {'word': 'MAKE', 'start': 170.5939375, 'end': 170.72568750000002}, {'word': 'YOU', 'start': 170.816125, 'end': 170.9276875}, {'word': 'CRY', 'start': 170.9373125, 'end': 171.04887499999998}, {'word': 'I', 'start': 171.6241875, 'end': 171.836875}, {'word': 'GOTTA', 'start': 172.1090625, 'end': 172.2409375}, {'word': 'MAKE', 'start': 172.2706875, 'end': 172.50356250000002}, {'word': 'YOU', 'start': 172.5535, 'end': 172.8065625}]}, {'start': 172.816125, 'end': 181.1708125, 'segment_word_list': [{'word': 'CRY', 'start': 172.816125, 'end': 172.9681875}, {'word': 'NEVER', 'start': 173.2201875, 'end': 174.0794375}, {'word': 'GONNA', 'start': 174.189875, 'end': 174.6046875}, {'word': 'TELL', 'start': 174.6545, 'end': 174.86731250000003}, {'word': 'THE', 'start': 174.9373125, 'end': 175.00868749999998}, {'word': 'LIE', 'start': 175.018125, 'end': 175.0895}, {'word': 'AND', 'start': 175.240375, 'end': 175.4129375}, {'word': 'HURT', 'start': 175.462625, 'end': 176.74625}, {'word': 'YOU', 'start': 176.816125, 'end': 176.88762499999999}, {'word': 'IF', 'start': 179.330625, 'end': 179.5025}, {'word': 'YOU', 'start': 179.5115, 'end': 179.66325}, {'word': 'ARE', 'start': 179.833125, 'end': 179.96475}, {'word': 'GONNA', 'start': 179.9738125, 'end': 180.2260625}, {'word': 'GIVE', 'start': 180.235125, 'end': 180.4270625}, {'word': 'NEVER', 'start': 180.536625, 'end': 180.8491875}]}, {'start': 180.85825, 'end': 188.4238125, 'segment_word_list': [{'word': 'GONNA', 'start': 180.85825, 'end': 180.989875}, {'word': 'GIVE', 'start': 180.9989375, 'end': 181.1708125}, {'word': 'IF', 'start': 181.442375, 'end': 181.5345}, {'word': 'YOU', 'start': 181.604, 'end': 181.71631250000002}, {'word': 'ARE', 'start': 182.2706875, 'end': 182.42337500000002}, {'word': 'NEVER', 'start': 183.563625, 'end': 183.857875}, {'word': 'GONNA', 'start': 183.9070625, 'end': 184.54475}, {'word': 'RUN', 'start': 184.5535, 'end': 184.686125}, {'word': 'AROUND', 'start': 184.7959375, 'end': 185.07000000000002}, {'word': 'IT', 'start': 185.1191875, 'end': 185.17100000000002}, {'word': 'YOU', 'start': 185.2201875, 'end': 185.59537500000002}, {'word': 'SAID', 'start': 185.6848125, 'end': 186.120625}, {'word': 'YOU', 'start': 186.4323125, 'end': 186.6256875}, {'word': \"YOU'RE\", 'start': 187.72525, 'end': 187.8783125}, {'word': 'GONNA', 'start': 187.92725, 'end': 188.060125}]}, {'start': 188.1090625, 'end': 196.585875, 'segment_word_list': [{'word': 'MAKE', 'start': 188.1090625, 'end': 188.2419375}, {'word': 'YOU', 'start': 188.2505, 'end': 188.4238125}, {'word': 'CRY', 'start': 188.4323125, 'end': 188.605625}, {'word': 'NEVER', 'start': 189.2, 'end': 189.716875}, {'word': 'GONNA', 'start': 189.72525, 'end': 189.85825}, {'word': 'SAY', 'start': 189.8868125, 'end': 189.95918749999998}, {'word': 'GOODBYE', 'start': 189.987875, 'end': 190.322875}, {'word': 'NEVER', 'start': 191.2201875, 'end': 191.7169375}, {'word': 'GONNA', 'start': 191.8464375, 'end': 192.060375}, {'word': 'TELL', 'start': 192.12925, 'end': 192.2421875}, {'word': 'THE', 'start': 192.2505, 'end': 192.34324999999998}, {'word': 'LIE', 'start': 192.3515, 'end': 192.44424999999998}, {'word': 'AND', 'start': 193.462625, 'end': 193.6160625}, {'word': 'HURT', 'start': 193.6848125, 'end': 194.1413125}, {'word': 'YOU', 'start': 194.3110625, 'end': 194.38368749999998}]}, {'start': 196.23025, 'end': 204.2025625, 'segment_word_list': [{'word': 'IF', 'start': 196.23025, 'end': 196.4040625}, {'word': 'YOU', 'start': 196.4120625, 'end': 196.585875}, {'word': 'ARE', 'start': 196.715125, 'end': 197.010125}, {'word': 'NEVER', 'start': 197.6848125, 'end': 197.85875}, {'word': 'GONNA', 'start': 197.8868125, 'end': 198.2425625}, {'word': 'LET', 'start': 198.2505, 'end': 198.48499999999999}, {'word': 'YOU', 'start': 198.513125, 'end': 198.6668125}, {'word': 'DOWN', 'start': 198.6746875, 'end': 198.788}, {'word': 'NEVER', 'start': 199.240375, 'end': 199.576}, {'word': 'GONNA', 'start': 199.604, 'end': 199.7578125}, {'word': 'RUN', 'start': 199.92725, 'end': 200.2426875}, {'word': 'AROUND', 'start': 200.5736875, 'end': 200.94975}, {'word': 'IT', 'start': 201.0989375, 'end': 201.15175}, {'word': 'YOU', 'start': 201.462625, 'end': 202.08125}, {'word': 'SAID', 'start': 202.088875, 'end': 202.5256875}]}, {'start': 202.614125, 'end': 209.90662500000002, 'segment_word_list': [{'word': 'YOU', 'start': 202.614125, 'end': 202.747875}, {'word': 'IF', 'start': 204.1090625, 'end': 204.2025625}, {'word': 'YOU', 'start': 204.2505, 'end': 204.32375}, {'word': 'ARE', 'start': 204.3313125, 'end': 204.46518749999998}, {'word': 'GONNA', 'start': 204.614125, 'end': 204.7681875}, {'word': 'MAKE', 'start': 204.77575, 'end': 204.86925}, {'word': 'YOU', 'start': 204.8969375, 'end': 204.9701875}, {'word': 'CRY', 'start': 205.018125, 'end': 205.1318125}, {'word': 'NEVER', 'start': 205.301, 'end': 205.5561875}, {'word': 'GONNA', 'start': 205.563625, 'end': 205.75825}, {'word': 'SAY', 'start': 205.7858125, 'end': 205.899625}, {'word': 'GOODBYE', 'start': 205.92725, 'end': 206.222875}, {'word': 'NEVER', 'start': 208.1246875, 'end': 208.7205625}, {'word': 'GONNA', 'start': 208.7478125, 'end': 209.0019375}, {'word': 'LET', 'start': 209.0091875, 'end': 209.1829375}]}]\n"
     ]
    }
   ],
   "source": [
    "# path = \"../../data/massive_youtube_data\"\n",
    "path = \"/home/kastan/thesis/data/simple_test_data\"\n",
    "data_preprocessor = YoutubeDataPreprocessor(path)\n",
    "test_file = '/home/kastan/thesis/data/simple_test_data/rick_roll.mp4'\n",
    "# test_file = \"/home/kastan/thesis/data/whisper_directory/Rick Astley - Never Gonna Give You Up (Official Music Video).mp4\"\n",
    "\n",
    "# import cProfile\n",
    "# cProfile.run('data_preprocessor.process_video(test_file)')\n",
    "\n",
    "result = data_preprocessor.process_video(test_file)\n",
    "print(result)\n",
    "# data_preprocessor.process_video(test_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kastan/utils/miniconda3/envs/nlp/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import subprocess\n",
    "import os\n",
    "# Imports \n",
    "from lhotse import CutSet, RecordingSet, align_with_torchaudio, annotate_with_whisper\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint\n",
    "from dataclasses import asdict\n",
    "import torch\n",
    "from os import path\n",
    "from pydub import AudioSegment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning audio files (*wav): 1it [00:00, 1271.39it/s]\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "path = \"/home/kastan/thesis/data/whisper_directory\"\n",
    "# path = \"/home/kastan/thesis/video-pretrained-transformer/whisper_audio/audio_test\"\n",
    "recordings = RecordingSet.from_dir(path, pattern = \"*wav\")\n",
    "# recordings = RecordingSet.from_dir(\"/home/kastan/thesis/data/simple_test_data\", pattern=\"*.mp4\")\n",
    "cuts = annotate_with_whisper(recordings, device = device)\n",
    "cuts_aligned = align_with_torchaudio(cuts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning audio files (*.wav): 1it [00:00, 1506.57it/s]\n"
     ]
    }
   ],
   "source": [
    "path = \"/home/kastan/thesis/data/whisper_directory/Rick Astley - Never Gonna Give You Up (Official Music Video).mp4\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "dir = '/'.join(path.split(\"/\")[:-1])\n",
    "recordings = RecordingSet.from_dir(dir, pattern=\"*.wav\")\n",
    "cuts = annotate_with_whisper(recordings, device = device)\n",
    "cuts_aligned = align_with_torchaudio(cuts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "for cut in cuts_aligned:\n",
    "    cut_extract = asdict(cut)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning audio files (*.wav): 1it [00:00, 1248.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returning prematurely...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/kastan/thesis/video-pretrained-transformer/data_preprocessing/Custom_PyTorch_Dataset.ipynb Cell 23\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B100.107.136.74/home/kastan/thesis/video-pretrained-transformer/data_preprocessing/Custom_PyTorch_Dataset.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m data_preprocessor \u001b[39m=\u001b[39m YoutubeDataPreprocessor(path)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B100.107.136.74/home/kastan/thesis/video-pretrained-transformer/data_preprocessing/Custom_PyTorch_Dataset.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m test_file \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m/home/kastan/thesis/data/whisper_directory/Rick Astley - Never Gonna Give You Up (Official Music Video).mp4\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B100.107.136.74/home/kastan/thesis/video-pretrained-transformer/data_preprocessing/Custom_PyTorch_Dataset.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m data_preprocessor\u001b[39m.\u001b[39;49mprocess_video(test_file)\n",
      "\u001b[1;32m/home/kastan/thesis/video-pretrained-transformer/data_preprocessing/Custom_PyTorch_Dataset.ipynb Cell 23\u001b[0m in \u001b[0;36mYoutubeDataPreprocessor.process_video\u001b[0;34m(self, video_name)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B100.107.136.74/home/kastan/thesis/video-pretrained-transformer/data_preprocessing/Custom_PyTorch_Dataset.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=123'>124</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprocess_video\u001b[39m(\u001b[39mself\u001b[39m, video_name):\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B100.107.136.74/home/kastan/thesis/video-pretrained-transformer/data_preprocessing/Custom_PyTorch_Dataset.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=124'>125</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcaption_preprocessor\u001b[39m.\u001b[39mprocess_mp4(video_name)\n\u001b[0;32m--> <a href='vscode-notebook-cell://ssh-remote%2B100.107.136.74/home/kastan/thesis/video-pretrained-transformer/data_preprocessing/Custom_PyTorch_Dataset.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=125'>126</a>\u001b[0m     segment_timestamps \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcaption_preprocessor\u001b[39m.\u001b[39;49mget_segments_thresholded()\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B100.107.136.74/home/kastan/thesis/video-pretrained-transformer/data_preprocessing/Custom_PyTorch_Dataset.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=126'>127</a>\u001b[0m     \u001b[39m# print(segment_timestamps)\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B100.107.136.74/home/kastan/thesis/video-pretrained-transformer/data_preprocessing/Custom_PyTorch_Dataset.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=127'>128</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m segment_timestamps\n",
      "File \u001b[0;32m~/thesis/video-pretrained-transformer/data_preprocessing/../../video-pretrained-transformer/whisper_audio/CaptionPreprocessing.py:72\u001b[0m, in \u001b[0;36mCaptionPreprocessing.get_segments_thresholded\u001b[0;34m(self, time, threshold)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcut:\n\u001b[1;32m     71\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcut \u001b[39m=\u001b[39m get_cut(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmp3_path)\n\u001b[0;32m---> 72\u001b[0m time_dict_list \u001b[39m=\u001b[39m to_time_dict()\n\u001b[1;32m     73\u001b[0m curr_dict_list \u001b[39m=\u001b[39m []\n\u001b[1;32m     74\u001b[0m index \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[0;32m~/thesis/video-pretrained-transformer/data_preprocessing/../../video-pretrained-transformer/whisper_audio/CaptionPreprocessing.py:63\u001b[0m, in \u001b[0;36mCaptionPreprocessing.get_segments_thresholded.<locals>.to_time_dict\u001b[0;34m()\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mto_time_dict\u001b[39m():\n\u001b[1;32m     61\u001b[0m     time_dict_list \u001b[39m=\u001b[39m []\n\u001b[0;32m---> 63\u001b[0m     \u001b[39mfor\u001b[39;00m supervision \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcut[\u001b[39m'\u001b[39;49m\u001b[39msupervisions\u001b[39;49m\u001b[39m'\u001b[39;49m]:\n\u001b[1;32m     64\u001b[0m         \u001b[39mif\u001b[39;00m supervision[\u001b[39m'\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mMusic\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m     65\u001b[0m             \u001b[39mcontinue\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0497ffde1df318912604fec7dc437cf596dddf2ca6f4de129c07bc0ec5975633"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
