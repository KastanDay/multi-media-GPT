{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deeplake\n",
    "import jsonlines\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import json\n",
    "import glob\n",
    "import traceback\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skvideo.io\n",
    "import imageio.v3 as iio\n",
    "import av\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 GB\n",
      "Dataset(path='/tmp/junk', tensors=[])\n",
      "\n",
      " tensor    htype    shape    dtype  compression\n",
      " -------  -------  -------  -------  ------- \n",
      "[69.]\n",
      "[69.]\n",
      "[69.]\n",
      "[69.]\n",
      "[69.]\n",
      "[69.]\n",
      "[69.]\n",
      "[69.]\n",
      "[69.]\n",
      "[69.]\n",
      "After update\n",
      "[420.]\n",
      "[420.]\n",
      "[420.]\n",
      "[420.]\n",
      "[420.]\n",
      "[69.]\n",
      "[69.]\n",
      "[69.]\n",
      "[69.]\n",
      "[69.]\n"
     ]
    }
   ],
   "source": [
    "import deeplake as dl\n",
    "import numpy as np\n",
    "import tqdm\n",
    "dataset_name = '/mnt/storage_ssd/v2_text_encode_results_parallel_15'\n",
    "dataset_name = '/tmp/junk'\n",
    "# dataset_name = '/mnt/storage_ssd/problem_file_only_whisper_results_parallel_15'\n",
    "# ds = dl.load(dataset_name)\n",
    "ds = dl.empty(dataset_name, overwrite=True)\n",
    "print(ds.size_approx() / 1e9, \"GB\")\n",
    "ds.summary()\n",
    "ds.create_tensor('hi',   htype='image', dtype=np.float32, sample_compression=None)\n",
    "\n",
    "video_files = set()\n",
    "with ds:\n",
    "  for i in range(10):\n",
    "    ds.hi.append(np.float32(69))\n",
    "\n",
    "for idx, sample in enumerate(ds):\n",
    "  print(sample.hi.data()['value'])\n",
    "  \n",
    "ds.hi[0:5] = [np.float32(420)] * 5\n",
    "print(\"After update\")\n",
    "for idx, sample in enumerate(ds):\n",
    "  print(sample.hi.data()['value'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0., 0., 0., ..., 0., 0., 0.], dtype=float32),\n",
       " array([0., 0., 0., ..., 0., 0., 0.], dtype=float32),\n",
       " array([0., 0., 0., ..., 0., 0., 0.], dtype=float32),\n",
       " array([0., 0., 0., ..., 0., 0., 0.], dtype=float32),\n",
       " array([0., 0., 0., ..., 0., 0., 0.], dtype=float32)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[np.zeros(1024, dtype=np.float32)] * 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[420.0, 420.0, 420.0, 420.0, 420.0]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[np.float32(420)] * 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/storage_ssd/clip_DUMMY_results_parallel_15 loaded successfully.\n",
      "3.44 GB\n",
      "Dataset(path='/mnt/storage_ssd/clip_DUMMY_results_parallel_15', tensors=['caption', 'caption_embedding', 'clip_last_hidden_states', 'clip_pooled_embedding', 'frames', 'segment_metadata', 'video_filename', 'video_filepath'])\n",
      "\n",
      "         tensor            htype             shape              dtype  compression\n",
      "         -------          -------           -------            -------  ------- \n",
      "         caption           text            (24342, 1)            str     None   \n",
      "    caption_embedding      image     (24342, 0:70, 0:1024)     float16   None   \n",
      " clip_last_hidden_states   image     (24342, 0:577, 0:1024)    float32   None   \n",
      "  clip_pooled_embedding    image        (24342, 0:1024)        float32   None   \n",
      "         frames            image   (24342, 0:360, 0:640, 0:3)   uint8    None   \n",
      "    segment_metadata       json            (24342, 1)            str     None   \n",
      "     video_filename        text            (24342, 1)            str     None   \n",
      "     video_filepath        text            (24342, 1)            str     None   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [00:00, 87.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1024,)\n",
      "(577, 1024)\n",
      "(360, 640, 3)\n",
      "(1024,)\n",
      "(577, 1024)\n",
      "(360, 640, 3)\n",
      "(1024,)\n",
      "(577, 1024)\n",
      "(360, 640, 3)\n",
      "(1024,)\n",
      "(577, 1024)\n",
      "(360, 640, 3)\n",
      "(1024,)\n",
      "(577, 1024)\n",
      "(360, 640, 3)\n",
      "(1024,)\n",
      "(577, 1024)\n",
      "(360, 640, 3)\n",
      "(1024,)\n",
      "(577, 1024)\n",
      "(360, 640, 3)\n",
      "(1024,)\n",
      "(577, 1024)\n",
      "(360, 640, 3)\n",
      "(1024,)\n",
      "(577, 1024)\n",
      "(360, 640, 3)\n",
      "(1024,)\n",
      "(577, 1024)\n",
      "(360, 640, 3)\n",
      "(1024,)\n",
      "(577, 1024)\n",
      "(360, 640, 3)\n",
      "(1024,)\n",
      "(577, 1024)\n",
      "(360, 640, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import deeplake as dl\n",
    "import tqdm\n",
    "BATCH_NAME              = 'parallel_15'\n",
    "RESULTS_DATASET_PATH    = f'/mnt/storage_ssd/clip_DUMMY_results_{BATCH_NAME}'\n",
    "ds = dl.load(RESULTS_DATASET_PATH)\n",
    "print(ds.size_approx() / 1e9, \"GB\")\n",
    "ds.summary()\n",
    "\n",
    "# video_files = set()\n",
    "for idx, sample in tqdm.tqdm(enumerate(ds)):\n",
    "  print(sample.clip_pooled_embedding.numpy().shape)\n",
    "  print(sample.clip_last_hidden_states.numpy().shape)\n",
    "  print(sample.frames.numpy().shape)\n",
    "  if sample.clip_pooled_embedding.numpy().shape == (0,):\n",
    "    print(\"YES WE GOT IT: {idx}\")\n",
    "  if idx > 10:\n",
    "    break\n",
    "  # if sample.clip_pooled_embedding.numpy().shape == (0,) or sample.clip_last_hidden_states.numpy().shape == (0,):\n",
    "  # if len(video_files) > 15:\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/storage_ssd/v2_text_encode_results_parallel_15 loaded successfully.\n",
      "2.58 GB\n",
      "Dataset(path='/mnt/storage_ssd/v2_text_encode_results_parallel_15', tensors=['caption', 'caption_embedding', 'segment_metadata', 'video_filename', 'video_filepath'])\n",
      "\n",
      "      tensor         htype           shape           dtype  compression\n",
      "      -------       -------         -------         -------  ------- \n",
      "      caption        text         (24342, 1)          str     None   \n",
      " caption_embedding   image   (24342, 0:70, 0:1024)  float16   None   \n",
      " segment_metadata    json         (24342, 1)          str     None   \n",
      "  video_filename     text         (24342, 1)          str     None   \n",
      "  video_filepath     text         (24342, 1)          str     None   \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'/mnt/storage_hdd/thesis/yt_1b_dataset/yt_1b_train/parallel_15/JCd7JdAsvI8_iBiology Techniques_14308_Budding of Enveloped Viruses - Stephen Harrison (Harvard⧸HHMI).webm',\n",
       " '/mnt/storage_hdd/thesis/yt_1b_dataset/yt_1b_train/parallel_15/JCdeimcQ3m0_KPIX CBS SF Bay Area_101532_Post-Debate Fact Check： Tulsi Gabbard Calls Out Kamala Harris.webm',\n",
       " \"/mnt/storage_hdd/thesis/yt_1b_dataset/yt_1b_train/parallel_15/JCg_qxJ-WcQ_WrecklessEating_10325_Arby's Ultimate Chocolate Shake Review - Wreckless Eating.webm\",\n",
       " '/mnt/storage_hdd/thesis/yt_1b_dataset/yt_1b_train/parallel_15/JccYTrBLmVI_ThugSniperx_109138_Part 1 How to Camo an Airsoft Gun.webm',\n",
       " '/mnt/storage_hdd/thesis/yt_1b_dataset/yt_1b_train/parallel_15/PAMS89N5RKQ_N P_1573_George W. Bush speech at Reagan Funeral.webm',\n",
       " '/mnt/storage_hdd/thesis/yt_1b_dataset/yt_1b_train/parallel_15/PAMqISmpU80_Rugby League Week_536_RLW TV： Cordner and Waerea-Hargreaves on their grand final rematch with Manly ｜ Rugby League Week.webm',\n",
       " '/mnt/storage_hdd/thesis/yt_1b_dataset/yt_1b_train/parallel_15/PANh8k0VaQ8_Audiofied_7131_Sennheiser IE 300 Review： Crazy Good In-Ears!.webm',\n",
       " '/mnt/storage_hdd/thesis/yt_1b_dataset/yt_1b_train/parallel_15/PCmte2hjC2A_Oana C_19889_Webber and Bailey.webm',\n",
       " '/mnt/storage_hdd/thesis/yt_1b_dataset/yt_1b_train/parallel_15/Pa-maK8ernM_Gauging Gadgets_3579_How to Update Firmware on Kasa Smart Devices - Smart Plug, Bulbs, Cameras, Switches.webm',\n",
       " '/mnt/storage_hdd/thesis/yt_1b_dataset/yt_1b_train/parallel_15/PaKplbhmAG4_AJ SIMMONS_749_I ALMOST QUIT BUSINESS AND GOT A JOB BECAUSE MY CUSTOMER FIRED ME.webm',\n",
       " '/mnt/storage_hdd/thesis/yt_1b_dataset/yt_1b_train/parallel_15/PamPpLUKrjg_Mars Gadgets_6302_ALERT： 5 Mercedes NEW All-Electric Vehicles Will Doom The EV Industry ｜ 2022 Mercedes Electric cars.webm',\n",
       " '/mnt/storage_hdd/thesis/yt_1b_dataset/yt_1b_train/parallel_15/Pao5LF5bMPE_rileyphotos_347_Meeting the Tiger King of the UK..webm',\n",
       " '/mnt/storage_hdd/thesis/yt_1b_dataset/yt_1b_train/parallel_15/jCciuZa8yXI_The Fumble_38323_Kevin Durant CAUGHT Hitting On Hottie At OKC Game & FINALLY Opens Up About BURNER Accounts!.webm',\n",
       " '/mnt/storage_hdd/thesis/yt_1b_dataset/yt_1b_train/parallel_15/jCeNqqSxXrU_CBC News： The National_6266_The Winnipeg Falcons： Hockey gold medallists and WWI heroes all on one team.webm',\n",
       " '/mnt/storage_hdd/thesis/yt_1b_dataset/yt_1b_train/parallel_15/jCgKlEJwHDU_Kylie Aaliyah_36024_HOW I EDIT MY YOUTUBE VIDEOS - INTRO, OUTRO, VOICEOVERS & MORE + FINAL CUT PRO HACK ｜ KYLIE AALIYAH.webm',\n",
       " '/mnt/storage_hdd/thesis/yt_1b_dataset/yt_1b_train/parallel_15/jcH-stR8a88_TXSVIKING !_701_MINIX Mini PC.webm'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import deeplake as dl\n",
    "import tqdm\n",
    "dataset_name = '/mnt/storage_ssd/v2_text_encode_results_parallel_15'\n",
    "# dataset_name = '/mnt/storage_ssd/v2_whisper_results_parallel_15'\n",
    "# dataset_name = '/mnt/storage_ssd/problem_file_only_whisper_results_parallel_15'\n",
    "ds = dl.load(dataset_name)\n",
    "print(ds.size_approx() / 1e9, \"GB\")\n",
    "ds.summary()\n",
    "\n",
    "video_files = set()\n",
    "for idx, sample in enumerate(ds):\n",
    "  video_files.add(sample.video_filepath.data()['value'])\n",
    "  if len(video_files) > 15:\n",
    "    break\n",
    "video_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export PATH=$PATH:$HOME/bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/kastan/utils/mambaforge/envs/nlp_v2/bin:/home/kastan/.vscode-server-insiders/bin/64a739f7aa1092187348afa9378931d47683be12/bin/remote-cli:/home/kastan/utils/mambaforge/envs/nlp_v2/bin:/home/kastan/utils/mambaforge/condabin:/usr/local/cuda/bin:/home/kastan/.cargo/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/home/kastan/.vscode-server-insiders/bin/64a739f7aa1092187348afa9378931d47683be12/bin/remote-cli:/home/kastan/utils/mambaforge/envs/nlp_v2/bin:/home/kastan/utils/mambaforge/condabin:/usr/local/cuda/bin:/home/kastan/.cargo/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/home/kastan/utils/mambaforge/envs/nlp_v2/lib/python3.8/site-packages/decord\n"
     ]
    }
   ],
   "source": [
    "!echo $PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/storage_hdd/thesis/yt_1b_dataset/yt_1b_train/parallel_15/Pa-maK8ernM_Gauging Gadgets_3579_How to Update Firmware on Kasa Smart Devices - Smart Plug, Bulbs, Cameras, Switches.webm\n",
      "(7, 360, 640, 3)\n",
      "30.0\n",
      "⏰ Time to extract 1 frame: 0.22 seconds\n",
      "/mnt/storage_hdd/thesis/yt_1b_dataset/yt_1b_train/parallel_15/PCmte2hjC2A_Oana C_19889_Webber and Bailey.webm\n",
      "(7, 360, 624, 3)\n",
      "23.976023976023978\n",
      "⏰ Time to extract 1 frame: 0.36 seconds\n",
      "/mnt/storage_hdd/thesis/yt_1b_dataset/yt_1b_train/parallel_15/PAMS89N5RKQ_N P_1573_George W. Bush speech at Reagan Funeral.webm\n",
      "(7, 360, 540, 3)\n",
      "29.97002997002997\n",
      "⏰ Time to extract 1 frame: 0.64 seconds\n",
      "/mnt/storage_hdd/thesis/yt_1b_dataset/yt_1b_train/parallel_15/jCciuZa8yXI_The Fumble_38323_Kevin Durant CAUGHT Hitting On Hottie At OKC Game & FINALLY Opens Up About BURNER Accounts!.webm\n",
      "(7, 360, 640, 3)\n",
      "29.97002997002997\n",
      "⏰ Time to extract 1 frame: 0.26 seconds\n",
      "/mnt/storage_hdd/thesis/yt_1b_dataset/yt_1b_train/parallel_15/Pao5LF5bMPE_rileyphotos_347_Meeting the Tiger King of the UK..webm\n",
      "(7, 360, 640, 3)\n",
      "25.0\n",
      "⏰ Time to extract 1 frame: 0.42 seconds\n",
      "/mnt/storage_hdd/thesis/yt_1b_dataset/yt_1b_train/parallel_15/PaKplbhmAG4_AJ SIMMONS_749_I ALMOST QUIT BUSINESS AND GOT A JOB BECAUSE MY CUSTOMER FIRED ME.webm\n",
      "(7, 360, 202, 3)\n",
      "30.0\n",
      "⏰ Time to extract 1 frame: 0.38 seconds\n",
      "/mnt/storage_hdd/thesis/yt_1b_dataset/yt_1b_train/parallel_15/PAMqISmpU80_Rugby League Week_536_RLW TV： Cordner and Waerea-Hargreaves on their grand final rematch with Manly ｜ Rugby League Week.webm\n",
      "(7, 360, 640, 3)\n",
      "25.0\n",
      "⏰ Time to extract 1 frame: 0.24 seconds\n",
      "/mnt/storage_hdd/thesis/yt_1b_dataset/yt_1b_train/parallel_15/JCdeimcQ3m0_KPIX CBS SF Bay Area_101532_Post-Debate Fact Check： Tulsi Gabbard Calls Out Kamala Harris.webm\n",
      "(7, 360, 640, 3)\n",
      "29.97002997002997\n",
      "⏰ Time to extract 1 frame: 0.23 seconds\n",
      "/mnt/storage_hdd/thesis/yt_1b_dataset/yt_1b_train/parallel_15/JCg_qxJ-WcQ_WrecklessEating_10325_Arby's Ultimate Chocolate Shake Review - Wreckless Eating.webm\n",
      "(7, 360, 640, 3)\n",
      "29.97\n",
      "⏰ Time to extract 1 frame: 0.24 seconds\n",
      "/mnt/storage_hdd/thesis/yt_1b_dataset/yt_1b_train/parallel_15/JCd7JdAsvI8_iBiology Techniques_14308_Budding of Enveloped Viruses - Stephen Harrison (Harvard⧸HHMI).webm\n",
      "(7, 360, 480, 3)\n",
      "29.97002997002997\n",
      "⏰ Time to extract 1 frame: 0.18 seconds\n",
      "/mnt/storage_hdd/thesis/yt_1b_dataset/yt_1b_train/parallel_15/JccYTrBLmVI_ThugSniperx_109138_Part 1 How to Camo an Airsoft Gun.webm\n",
      "(7, 360, 480, 3)\n",
      "30.0\n",
      "⏰ Time to extract 1 frame: 0.22 seconds\n",
      "/mnt/storage_hdd/thesis/yt_1b_dataset/yt_1b_train/parallel_15/jcH-stR8a88_TXSVIKING !_701_MINIX Mini PC.webm\n",
      "(7, 360, 640, 3)\n",
      "29.97002997002997\n",
      "⏰ Time to extract 1 frame: 0.27 seconds\n",
      "/mnt/storage_hdd/thesis/yt_1b_dataset/yt_1b_train/parallel_15/PANh8k0VaQ8_Audiofied_7131_Sennheiser IE 300 Review： Crazy Good In-Ears!.webm\n",
      "(7, 360, 640, 3)\n",
      "25.0\n",
      "⏰ Time to extract 1 frame: 0.26 seconds\n",
      "/mnt/storage_hdd/thesis/yt_1b_dataset/yt_1b_train/parallel_15/jCgKlEJwHDU_Kylie Aaliyah_36024_HOW I EDIT MY YOUTUBE VIDEOS - INTRO, OUTRO, VOICEOVERS & MORE + FINAL CUT PRO HACK ｜ KYLIE AALIYAH.webm\n",
      "(7, 360, 640, 3)\n",
      "29.97002997002997\n",
      "⏰ Time to extract 1 frame: 0.44 seconds\n",
      "/mnt/storage_hdd/thesis/yt_1b_dataset/yt_1b_train/parallel_15/PamPpLUKrjg_Mars Gadgets_6302_ALERT： 5 Mercedes NEW All-Electric Vehicles Will Doom The EV Industry ｜ 2022 Mercedes Electric cars.webm\n",
      "(7, 360, 640, 3)\n",
      "23.976023976023978\n",
      "⏰ Time to extract 1 frame: 0.57 seconds\n",
      "/mnt/storage_hdd/thesis/yt_1b_dataset/yt_1b_train/parallel_15/jCeNqqSxXrU_CBC News： The National_6266_The Winnipeg Falcons： Hockey gold medallists and WWI heroes all on one team.webm\n",
      "(7, 360, 640, 3)\n",
      "29.97002997002997\n",
      "⏰ Time to extract 1 frame: 0.39 seconds\n",
      "5.310220497005503\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from PIL import Image\n",
    "total_time = 0\n",
    "from decord import VideoReader, cpu\n",
    "\n",
    "# video_files.remove(\"/mnt/storage_hdd/thesis/yt_1b_dataset/yt_1b_train/parallel_15/jCciuZa8yXI_The Fumble_38323_Kevin Durant CAUGHT Hitting On Hottie At OKC Game & FINALLY Opens Up About BURNER Accounts!.webm\")\n",
    "# video_files.add   (\"/mnt/storage_hdd/thesis/yt_1b_dataset/yt_1b_train/parallel_15/jCciuZa8yXI_The Fumble_38323_Kevin Durant CAUGHT Hitting On Hottie At OKC Game & FINALLY Opens Up About BURNER Accounts.webm\")\n",
    "# video_files.remove(\"/mnt/storage_hdd/thesis/yt_1b_dataset/yt_1b_train/parallel_15/PAMqISmpU80_Rugby League Week_536_RLW TV： Cordner and Waerea-Hargreaves on their grand final rematch with Manly Rugby League Week.webm\")\n",
    "# video_files.add   (\"/mnt/storage_hdd/thesis/yt_1b_dataset/yt_1b_train/parallel_15/PAMqISmpU80_Rugby League Week_536_RLW TV Cordner and Waerea-Hargreaves on their grand final rematch with Manly Rugby League Week.webm\")\n",
    "\n",
    "import traceback\n",
    "import inspect\n",
    "\n",
    "for video_file in video_files:\n",
    "    try:\n",
    "        print(video_file)\n",
    "        start_time = time.monotonic()\n",
    "        vr = VideoReader(str(video_file), ctx=cpu(0), num_threads=1)\n",
    "        frames2 = vr.get_batch([1, 25, 55, 68, 43, 323, 333])\n",
    "        print(frames2.asnumpy().shape)\n",
    "        print(vr.get_avg_fps())\n",
    "\n",
    "        time_per_frame = time.monotonic() - start_time\n",
    "        total_time += time_per_frame\n",
    "        print(f\"⏰ Time to extract 1 frame: {time_per_frame:.2f} seconds\")\n",
    "        # display(Image.fromarray(frame))\n",
    "    except Exception as e:\n",
    "        print(f\"❌❌ Error in: {e}\")\n",
    "        print(traceback.print_exc())\n",
    "    \n",
    "print(total_time)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# input data format\n",
    "\n",
    "```\n",
    "one_segment_output = {\n",
    "    \"video_stem\": str(Path(video_filepath).stem),\n",
    "    \"segment_id\": str(Path(video_filepath).stem) + f\"_{i}\",\n",
    "    \"segment_index\": np.int16(i),\n",
    "    \"total_segments\": np.int16(len(whisper_segments)),\n",
    "    \"segment_total_time\": whisper_segments[i]['end'] - whisper_segments[i]['start'],\n",
    "    \"captions\": whisper_segments[i]['caption'],\n",
    "    \"segment_start_time\": whisper_segments[i]['start'],\n",
    "    \"segment_end_time\": whisper_segments[i]['end'],\n",
    "    \"num_frames_per_segment\": np.int16(self.num_frames),\n",
    "    \"frame_embeddings\": image_feature,\n",
    "    \"text_caption_embeddings\": caption_feature,\n",
    "    \"segment_frames\": segment_frame,\n",
    "    \"frame_embeddings_shape\": image_feature.shape,          # trying the FLATTEN technique!\n",
    "    \"text_caption_embeddings_shape\": caption_feature.shape,\n",
    "    \"segment_frames_shape\": segment_frame.shape,\n",
    "    # \"scene_graph_captions\": scene_graph_feature -- to be added in the subsequent step.\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BASE_DIR            = '/mnt/storage_hdd/thesis/yt_1b_dataset/yt_1b_train/'\n",
    "BASE_DIR            = '/mnt/storage_ssd/'\n",
    "BATCH_NAME          = 'parallel_15'\n",
    "# BASE_DIR            = '/scratch/bbki/kastanday/whisper'\n",
    "# MODEL_SAVE_PATH     = f'{BASE_DIR}/MODEL_CHECKPOINTS/{MODEL_VERSION_NAME}'\n",
    "REMOTE_WHISPER_FILE = f'{BASE_DIR}/{BATCH_NAME}_whisper_output.jsonl'\n",
    "REMOTE_CLIP_DIR     = f'{BASE_DIR}/{BATCH_NAME}_clip_output'\n",
    "REMOTE_SCENE_FILE   = f'{BASE_DIR}/{BATCH_NAME}_scene_output.jsonl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@deeplake.compute\n",
    "def file_to_deeplake(clip_path_and_scene_graph, sample_out):\n",
    "    clip_npz_path, scene_seg = clip_path_and_scene_graph\n",
    "    try:\n",
    "        np_loaded = np.load(clip_npz_path, allow_pickle=True)\n",
    "        scene_seg_list = json.loads(scene_seg)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load compressed numpy: {e}\")\n",
    "        return -1\n",
    "    \n",
    "    # iterate over segments\n",
    "    for segment_index in range(np_loaded['arr_0'].item()['total_segments']):\n",
    "        try:\n",
    "            # frame_embedding       = np_loaded[f'arr_{segment_index}'].item()['frame_embeddings']\n",
    "            # caption_embedding     = np_loaded[f'arr_{segment_index}'].item()['text_caption_embeddings']\n",
    "            video_stem = np_loaded[f'arr_{segment_index}'].item()[\"video_stem\"]\n",
    "            segment_id = np_loaded[f'arr_{segment_index}'].item()[\"segment_id\"]\n",
    "            segment_index_val = np_loaded[f'arr_{segment_index}'].item()[\"segment_index\"]\n",
    "            total_segments = np_loaded[f'arr_{segment_index}'].item()[\"total_segments\"]\n",
    "            segment_total_time = np_loaded[f'arr_{segment_index}'].item()[\"segment_total_time\"]\n",
    "            captions = np_loaded[f'arr_{segment_index}'].item()[\"captions\"]\n",
    "            segment_start_time = np_loaded[f'arr_{segment_index}'].item()[\"segment_start_time\"]\n",
    "            segment_end_time = np_loaded[f'arr_{segment_index}'].item()[\"segment_end_time\"]\n",
    "            num_frames_per_segment = np_loaded[f'arr_{segment_index}'].item()[\"num_frames_per_segment\"]\n",
    "            frame_embeddings = np_loaded[f'arr_{segment_index}'].item()[\"frame_embeddings\"]\n",
    "            text_caption_embeddings = np_loaded[f'arr_{segment_index}'].item()[\"text_caption_embeddings\"]\n",
    "            segment_frames = np_loaded[f'arr_{segment_index}'].item()[\"segment_frames\"]\n",
    "            frame_embeddings_shape = np_loaded[f'arr_{segment_index}'].item()[\"frame_embeddings_shape\"]\n",
    "            text_caption_embeddings_shape = np_loaded[f'arr_{segment_index}'].item()[\"text_caption_embeddings_shape\"]\n",
    "            segment_frames_shape = np_loaded[f'arr_{segment_index}'].item()[\"segment_frames_shape\"]\n",
    "            \n",
    "            local_segment_metadata = {\n",
    "                'video_stem': video_stem,\n",
    "                'segment_id': segment_id,\n",
    "                'segment_index': int(segment_index_val),\n",
    "                'total_segments': int(total_segments),\n",
    "                'captions': captions,\n",
    "                'segment_total_time': float(segment_total_time),\n",
    "                'segment_start_time': float(segment_start_time),\n",
    "                'segment_end_time': float(segment_end_time),\n",
    "                'num_frames_per_segment': int(num_frames_per_segment),\n",
    "                'segment_frames_shape': segment_frames_shape,\n",
    "                'text_caption_embeddings_shape': text_caption_embeddings_shape,\n",
    "                'frame_embeddings_shape': frame_embeddings_shape,\n",
    "                'scene_graph_caption_txt': scene_seg_list[int(segment_index_val)]\n",
    "                # 'segment_frames': ,\n",
    "                # 'text_caption_embeddings': ,\n",
    "                # 'frame_embeddings': ,\n",
    "            }\n",
    "            \n",
    "            # add to dataset.\n",
    "            assert 336 * 336 * 3 == segment_frames.size # warning image dimension is hard coded \n",
    "            sample_out.segment_frames.append(segment_frames.reshape(336, 336, 3)) # warning image dimension is hard coded\n",
    "            sample_out.text_caption_embeddings.append(text_caption_embeddings)\n",
    "            sample_out.frame_embeddings.append(frame_embeddings)\n",
    "            sample_out.segment_metadata.append(local_segment_metadata)\n",
    "        except Exception as e:\n",
    "            # print(e)\n",
    "            traceback.print_exc()\n",
    "            continue\n",
    "    \n",
    "    return sample_out\n",
    "        \n",
    "    #     if sample_count >= 3:\n",
    "    #         break\n",
    "    # if sample_count >= 3:\n",
    "    #     break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clip_npz_path_list = []\n",
    "# scene_seg_list = []\n",
    "clip_path_and_scene_graph = []\n",
    "\n",
    "total_segments = 0\n",
    "with jsonlines.open(REMOTE_SCENE_FILE, 'r') as scene_reader:\n",
    "    # Zipping the scene graph with the clip + whisper embeddings\n",
    "    # itr over videos\n",
    "    for scene_graph_segments, clip_npz_path in tqdm.tqdm(zip(scene_reader, glob.glob(os.path.join(REMOTE_CLIP_DIR, '*'), recursive = True))):\n",
    "        # scene_seg_list.append(scene_graph_segments)\n",
    "        # clip_npz_path_list.append(clip_npz_path)\n",
    "        clip_path_and_scene_graph.append( (clip_npz_path, scene_graph_segments) )\n",
    "        total_segments += 1\n",
    "print(total_segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(clip_path_and_scene_graph) == total_segments\n",
    "len(clip_path_and_scene_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Create dataset '''\n",
    "\n",
    "dataset_name = '/mnt/storage_ssd/v0testing'\n",
    "ds = deeplake.empty(dataset_name, overwrite=True)\n",
    "\n",
    "with ds:\n",
    "    segment_frames          = ds.create_tensor('segment_frames', htype='image', dtype=np.uint8, sample_compression='jpg')\n",
    "    video_stem              = ds.create_tensor('video_stem', htype='text', dtype=str, sample_compression=None)\n",
    "    text_caption_embeddings = ds.create_tensor('text_caption_embeddings', htype='image', dtype=np.float16, sample_compression='lz4') # CLIP produces FP16 embeddings.\n",
    "    frame_embeddings        = ds.create_tensor('frame_embeddings', htype='image', dtype=np.float16, sample_compression='lz4') # compression: https://docs.deeplake.ai/en/latest/Compressions.html\n",
    "    segment_metadata        = ds.create_tensor('segment_metadata', htype='json', sample_compression='lz4') # compression: https://docs.deeplake.ai/en/latest/Compressions.html\n",
    "    \n",
    "    # clip_npz_path, sample_out, scene_seg\n",
    "    # file_to_deeplake().eval(clip_path_and_scene_graph, ds, num_workers = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "sample_count = 0\n",
    "start_time = time.monotonic()\n",
    "\n",
    "with jsonlines.open(REMOTE_SCENE_FILE, 'r') as scene_reader:\n",
    "    # Zipping the scene graph with the clip + whisper embeddings\n",
    "    # itr over videos\n",
    "    for scene_seg_list, clip_npz_path in tqdm.tqdm(zip(scene_reader, glob.glob(os.path.join(REMOTE_CLIP_DIR, '*'), recursive = True))):\n",
    "        sample_count += 1\n",
    "        if sample_count < 10_100:\n",
    "            continue \n",
    "        try:\n",
    "            np_loaded = np.load(clip_npz_path, allow_pickle=True)\n",
    "            object_list_of_str = []\n",
    "            scene_seg_list = json.loads(scene_seg_list)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to load compressed numpy: {e}\")\n",
    "            continue\n",
    "        \n",
    "        # iterate over segments\n",
    "        for segment_index in range(np_loaded['arr_0'].item()['total_segments']):\n",
    "            try:\n",
    "                # frame_embedding       = np_loaded[f'arr_{segment_index}'].item()['frame_embeddings']\n",
    "                # caption_embedding     = np_loaded[f'arr_{segment_index}'].item()['text_caption_embeddings']\n",
    "                video_stem = np_loaded[f'arr_{segment_index}'].item()[\"video_stem\"]\n",
    "                segment_id = np_loaded[f'arr_{segment_index}'].item()[\"segment_id\"]\n",
    "                segment_index_val = np_loaded[f'arr_{segment_index}'].item()[\"segment_index\"]\n",
    "                total_segments = np_loaded[f'arr_{segment_index}'].item()[\"total_segments\"]\n",
    "                segment_total_time = np_loaded[f'arr_{segment_index}'].item()[\"segment_total_time\"]\n",
    "                captions = np_loaded[f'arr_{segment_index}'].item()[\"captions\"]\n",
    "                segment_start_time = np_loaded[f'arr_{segment_index}'].item()[\"segment_start_time\"]\n",
    "                segment_end_time = np_loaded[f'arr_{segment_index}'].item()[\"segment_end_time\"]\n",
    "                num_frames_per_segment = np_loaded[f'arr_{segment_index}'].item()[\"num_frames_per_segment\"]\n",
    "                frame_embeddings = np_loaded[f'arr_{segment_index}'].item()[\"frame_embeddings\"]\n",
    "                text_caption_embeddings = np_loaded[f'arr_{segment_index}'].item()[\"text_caption_embeddings\"]\n",
    "                segment_frames = np_loaded[f'arr_{segment_index}'].item()[\"segment_frames\"]\n",
    "                frame_embeddings_shape = np_loaded[f'arr_{segment_index}'].item()[\"frame_embeddings_shape\"]\n",
    "                text_caption_embeddings_shape = np_loaded[f'arr_{segment_index}'].item()[\"text_caption_embeddings_shape\"]\n",
    "                segment_frames_shape = np_loaded[f'arr_{segment_index}'].item()[\"segment_frames_shape\"]\n",
    "                \n",
    "                local_segment_metadata = {\n",
    "                    'video_stem': video_stem,\n",
    "                    'segment_id': segment_id,\n",
    "                    'segment_index': int(segment_index_val),\n",
    "                    'total_segments': int(total_segments),\n",
    "                    'captions': captions,\n",
    "                    'segment_total_time': float(segment_total_time),\n",
    "                    'segment_start_time': float(segment_start_time),\n",
    "                    'segment_end_time': float(segment_end_time),\n",
    "                    'num_frames_per_segment': int(num_frames_per_segment),\n",
    "                    'segment_frames_shape': segment_frames_shape,\n",
    "                    'text_caption_embeddings_shape': text_caption_embeddings_shape,\n",
    "                    'frame_embeddings_shape': frame_embeddings_shape,\n",
    "                    'scene_graph_caption_txt': scene_seg_list[int(segment_index_val)]\n",
    "                    # 'segment_frames': ,\n",
    "                    # 'text_caption_embeddings': ,\n",
    "                    # 'frame_embeddings': ,\n",
    "                }\n",
    "                \n",
    "                # caption, caption_embed, clip_img_embed, scene_graph_caption, audio_embed (and segment_frame)\n",
    "                \n",
    "                # print(segment_frames.dtype)\n",
    "                # print(text_caption_embeddings.dtype)\n",
    "                # print(frame_embeddings.dtype)\n",
    "                # print(segment_frames.dtype)\n",
    "                \n",
    "                with ds:\n",
    "                    assert 336 * 336 * 3 == segment_frames.size # warning image dimension is hard coded \n",
    "                    ds.segment_frames.append(np.uint8(segment_frames.reshape(336, 336, 3))) # warning image dimension is hard coded\n",
    "                    ds.text_caption_embeddings.append(np.float16(text_caption_embeddings))\n",
    "                    ds.frame_embeddings.append(np.float16(frame_embeddings))\n",
    "                    ds.video_stem.append(str(video_stem))\n",
    "                    ds.segment_metadata.append(local_segment_metadata)\n",
    "                sample_count += 1\n",
    "                if sample_count % 50 == 0:\n",
    "                    print(\"examples_added: \", sample_count)\n",
    "                    print(f\"⏰ Runtime for 50 samples: {(time.monotonic() - start_time):.2f} seconds\")\n",
    "                    start_time = time.monotonic()\n",
    "            except Exception as e:\n",
    "                print(f\"Error while adding to dataset. Sample stem: {video_stem}\")\n",
    "                traceback.print_exc()\n",
    "                continue\n",
    "            # break\n",
    "        # break\n",
    "        #     if sample_count >= 3:\n",
    "        #         break\n",
    "        # if sample_count >= 3:\n",
    "        #     break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# has error on file: 10120 of 19199\n",
    "\n",
    "import deeplake\n",
    "# dataset_name = '/mnt/storage_ssd/v0testing'\n",
    "dataset_name = '/mnt/storage_ssd/FULL_v1_parallel_ingest_p15'\n",
    "read_lake = deeplake.load(dataset_name)\n",
    "\n",
    "read_lake.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_lake = deeplake.load(dataset_name)\n",
    "hub_lake = deeplake.empty(\"hub://kastan/v0_parallel_15\", overwrite=True)\n",
    "deeplake.copy(read_lake, hub_lake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read_lake.segment_metadata[2].data()['value'][total_segments]\n",
    "# read_lake.text_caption_embeddings[2].data()['value']\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "for i, sample in enumerate(read_lake):\n",
    "  if i % 50 == 0:\n",
    "    print(sample.segment_metadata.data())\n",
    "    \n",
    "    frame = sample.segment_frames.numpy()\n",
    "    frame_rgb = cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)\n",
    "    display(Image.fromarray(frame_rgb))\n",
    "  if i > 2000:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_lake.segment_metadata_json[0].data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data easily!!! All together! GOD BLESS\n",
    "\n",
    "from PIL import Image\n",
    "for i in range(3):\n",
    "  display(Image.fromarray(read_lake.segment_frames[i].numpy()))\n",
    "  print(read_lake.segment_metadata_json[i].data()['value']['captions'])\n",
    "  print(read_lake.segment_metadata_json[i].data()['value']['scene_graph_caption_txt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = deeplake.empty('/mnt/storage_ssd/trying_deeplake')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "images = ds.create_tensor('images', htype='image', sample_compression='jpg')\n",
    "\n",
    "with ds:\n",
    "    for _ in range(1000):  # 1000 random images\n",
    "        random_image = np.random.randint(0, 256, (100, 100, 3), dtype=np.uint8)  # 100x100 image with 3 channels\n",
    "        ds.images.append(random_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds.images[0].numpy()\n",
    "\n",
    "from PIL import Image\n",
    "Image.fromarray(ds.images[0].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_v2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e886ec343e9bf984999ac0f41f2df9adf20d1645c65a0a2833dfda78d79ad6ab"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
